{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mixtext.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+lGJUbVnI9jvLJWhJLA9y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graceyangfan/bilibili-video-code/blob/master/mixtext.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk_nF1Kr7bBm",
        "outputId": "301c37d1-389e-4f3f-96cd-062291ec26ed"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 24.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 33.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 24.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=9e8c365d052c391250b1363c22be82325828272db00adfa82d53365b23592334\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL2WA8Bw_k6m",
        "outputId": "855ec854-3994-4ae0-e444-5379fa34a217"
      },
      "source": [
        "!pip install boto3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/7f/4ade91fbb684c6f28a6e56028d9f9d2de4297761850d083579779f07c0de/boto3-1.16.25-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 8.8MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.8MB/s \n",
            "\u001b[?25hCollecting botocore<1.20.0,>=1.19.25\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/d5/c0c33ca15e31062220ac5964f3492409eaf90a5cf5399503cd8264f2f8e9/botocore-1.19.25-py2.py3-none-any.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 13.6MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.25->boto3) (2.8.1)\n",
            "Collecting urllib3<1.27,>=1.25.4; python_version != \"3.4\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/71/45d36a8df68f3ebb098d6861b2c017f3d094538c0fb98fa61d4dc43e69b9/urllib3-1.26.2-py2.py3-none-any.whl (136kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 45.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.25->boto3) (1.15.0)\n",
            "\u001b[31mERROR: requests 2.23.0 has requirement urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 1.26.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.16.25 botocore-1.19.25 jmespath-0.10.0 s3transfer-0.3.3 urllib3-1.26.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgWjEVgN7jgo",
        "outputId": "0919e42b-f019-499a-d635-3b62d6147ead"
      },
      "source": [
        "!pip install Fairseq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Fairseq\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/da/7c7032988dade3b21ccfd5b226e50b382abfd3459129d67240bb004506ae/fairseq-0.10.1-cp36-cp36m-manylinux1_x86_64.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from Fairseq) (1.18.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from Fairseq) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from Fairseq) (4.41.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from Fairseq) (0.29.21)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from Fairseq) (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from Fairseq) (0.8)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from Fairseq) (1.14.3)\n",
            "Collecting hydra-core\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/1f/7f502b9e37596164111655861370b08626f46f9e4524433c354f472765d4/hydra_core-1.0.4-py3-none-any.whl (122kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 31.5MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->Fairseq) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->Fairseq) (0.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->Fairseq) (2.20)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 30.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from hydra-core->Fairseq) (3.3.0)\n",
            "Collecting omegaconf>=2.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/e5/f6/043b6d255dd6fbf2025110cea35b87f4c5100a181681d8eab496269f0d5b/omegaconf-2.0.5-py3-none-any.whl\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core->Fairseq) (3.4.0)\n",
            "Collecting PyYAML>=5.1.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 32.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime, PyYAML\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp36-none-any.whl size=141230 sha256=ac26baa55b0a5e049047341d1255f4731b363c3afbc9061b72813d05f4f1ae79\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44619 sha256=8ca57c83d85ab1eb23ccda8b4a76b589eda6d625b83e05736ba84e49c5df1090\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "Successfully built antlr4-python3-runtime PyYAML\n",
            "Installing collected packages: portalocker, sacrebleu, antlr4-python3-runtime, PyYAML, omegaconf, hydra-core, Fairseq\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed Fairseq-0.10.1 PyYAML-5.3.1 antlr4-python3-runtime-4.8 hydra-core-1.0.4 omegaconf-2.0.5 portalocker-2.0.0 sacrebleu-1.4.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njgsM84q7rzz",
        "outputId": "d1d3c127-4de9-452c-974e-3baf4cc30f38"
      },
      "source": [
        "!pip install fastBPE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastBPE\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/37/f97181428a5d151501b90b2cebedf97c81b034ace753606a3cda5ad4e6e2/fastBPE-0.1.0.tar.gz\n",
            "Building wheels for collected packages: fastBPE\n",
            "  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp36-cp36m-linux_x86_64.whl size=481504 sha256=dba386f5746c6abe5a1252ce9c4feebeac8bafe6778198fc808a80dcb2b19a6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/0c/9c/fc62058b4d473a5602bcd3d3edfece796f123875379ea82d79\n",
            "Successfully built fastBPE\n",
            "Installing collected packages: fastBPE\n",
            "Successfully installed fastBPE-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMNw0No44bTU",
        "outputId": "da427c6b-d033-4c7c-ca1f-083eafb0f44e"
      },
      "source": [
        "!pip install -U deep_translator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deep_translator\n",
            "  Downloading https://files.pythonhosted.org/packages/54/fb/a85d75ae5cb25599bb3d078c7e6c7c9b22ff3ea1e64d9d5663a2101e1f4c/deep_translator-1.3.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from deep_translator) (4.6.3)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from deep_translator) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->deep_translator) (2.10)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/aa/4ef5aa67a9a62505db124a5cb5262332d1d4153462eb8fd89c9fa41e5d92/urllib3-1.25.11-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->deep_translator) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->deep_translator) (2020.11.8)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: deep-translator, urllib3\n",
            "  Found existing installation: urllib3 1.26.2\n",
            "    Uninstalling urllib3-1.26.2:\n",
            "      Successfully uninstalled urllib3-1.26.2\n",
            "Successfully installed deep-translator-1.3.2 urllib3-1.25.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOnItkz28_As",
        "outputId": "bb453a61-d844-48d7-d609-3da70c73b4cc"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/My Drive/MixText/code\"\n",
        "\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.idea',\n",
              " '__init__.py',\n",
              " '__pycache__',\n",
              " 'mixtext.py',\n",
              " 'model',\n",
              " 'normal_bert.py',\n",
              " 'normal_train.py',\n",
              " 'pytransformers',\n",
              " 'read_data.py',\n",
              " 'train.py',\n",
              " 'build',\n",
              " 'mixtext_test2.ipynb',\n",
              " 'mixText.csv',\n",
              " 'mixText_self_train.csv',\n",
              " 'mixtext.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVIqdgf6m0gG"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74PuiR7F3U8-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as Data\n",
        "from pytransformers import *\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import pickle\n",
        "import os\n",
        "import sklearn.model_selection\n",
        "import sklearn.preprocessing\n",
        "import joblib\n",
        "from deep_translator import GoogleTranslator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHfyZ89FiovN"
      },
      "source": [
        "def get_data(data_path,nlabels,max_seq_len=256, model='bert-base-chinese', train_aug=False):\n",
        "    # 加载bert的tokenizer类\n",
        "    tokenizer = BertTokenizer.from_pretrained(model)\n",
        "\n",
        "    def text_filter(sentence: str) -> str:\n",
        "        \"\"\"\n",
        "        过滤掉非汉字和标点符号和非数字\n",
        "        :param sentence:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        line = sentence.replace('\\n', '。')\n",
        "        # 过滤掉非汉字和标点符号和非数字\n",
        "        linelist = [word for word in line if\n",
        "                    word >= u'\\u4e00' and word <= u'\\u9fa5' or word in ['，', '。', '？', '！',\n",
        "                                                                        '：'] or word.isdigit()]\n",
        "        return ''.join(linelist)\n",
        "    def fliter_data(data):\n",
        "      data['content']=data['content'].astype(str)\n",
        "      data[\"text\"]=data[\"content\"].apply(lambda x:text_filter(x))\n",
        "      return data \n",
        "\n",
        "    train_df=pd.read_csv(data_path+\"/train_valid.csv\")\n",
        "    train_ul=pd.read_csv(data_path+\"/train_ul.csv\")\n",
        "    test_df=pd.read_csv(data_path+\"/test_df.csv\")\n",
        "\n",
        "    train_df=fliter_data(train_df)\n",
        "    train_ul=fliter_data(train_ul)\n",
        "    test_df=fliter_data(test_df)\n",
        "\n",
        "    total_unlabeled=pd.concat([train_ul,test_df])\n",
        "\n",
        "    ##get train and valid set with 对抗验证\n",
        "    train_labeled,valid_labeled=train_val_split(train_df,nlabels)\n",
        "\n",
        "\n",
        "    train_labeled_dataset = loader_labeled(list(train_labeled[\"text\"]),list(train_labeled[\"num_label\"]), tokenizer, max_seq_len, train_aug)\n",
        "    train_unlabeled_dataset = loader_unlabeled(list(total_unlabeled[\"text\"]),tokenizer, max_seq_len, train_aug)\n",
        "    val_dataset = loader_labeled(list(valid_labeled[\"text\"]),list(valid_labeled[\"num_label\"]), tokenizer, max_seq_len, train_aug)\n",
        "    test_dataset = loader_unlabeled(list(test_df[\"text\"]),tokenizer, max_seq_len, train_aug)\n",
        "    \n",
        "\n",
        "    return train_labeled_dataset, train_unlabeled_dataset, val_dataset, test_dataset, nlabels\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDwIohKoYwsj"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "def train_val_split(data,nlabels):\n",
        "    train_data=pd.DataFrame([])\n",
        "    valid_data=pd.DataFrame([])\n",
        "    for i in range(nlabels):\n",
        "      sub_data=data[data[\"num_label\"]==i].sort_values('is_test').reset_index(drop=True)\n",
        "      train_data=pd.concat([train_data,sub_data.iloc[:int(0.8 * len(sub_data)),]])\n",
        "      valid_data=pd.concat([valid_data,sub_data.iloc[int(0.8 * len(sub_data)):,]])\n",
        "      train_data=shuffle(train_data)\n",
        "      valid_data=shuffle(valid_data)\n",
        "      \n",
        "    return  train_data,valid_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_blqQEnhzV5"
      },
      "source": [
        "class loader_unlabeled(Dataset):\n",
        "    def __init__(self, dataset_text, tokenizer, max_seq_len, train_aug=False):\n",
        "        \"\"\"\n",
        "         # 无标签数据加载器\n",
        "        :param dataset_text:\n",
        "        :param unlabeled_idxs:\n",
        "        :param tokenizer:\n",
        "        :param max_seq_len:\n",
        "        :param train_aug: 是否做数据增强\n",
        "        \"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text = dataset_text\n",
        "        self.train_aug = train_aug\n",
        "        self.max_seq_len = max_seq_len\n",
        "        #做一个空的字典，保存数据增强后的文本\n",
        "        self.trans_dist = {}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def augment(self, text):\n",
        "        \"\"\"\n",
        "        数据增强, 翻译成英文，在翻译回中文\n",
        "        :param text: 单个文档的文本\n",
        "        :return:  新的列表，列表里面是生成后的文本\n",
        "        \"\"\"\n",
        "        TranslatorF= GoogleTranslator(source='auto', target='en')\n",
        "        TranslatorI= GoogleTranslator(source='auto', target='chinese (simplified)')\n",
        "        if text not in self.trans_dist:\n",
        "            text1 = TranslatorF.translate(text=text)\n",
        "            text2 = TranslatorI.translate(text=text1)\n",
        "            self.trans_dist[text] = text2\n",
        "        return self.trans_dist[text], text\n",
        "\n",
        "    def get_tokenized(self, text):\n",
        "        \"\"\"\n",
        "        :param text: 接收纯文本\n",
        "        :return:返回encode后的数字id，和原始长度\n",
        "        \"\"\"\n",
        "        tokens = self.tokenizer.tokenize(text)\n",
        "        if len(tokens) > self.max_seq_len:\n",
        "            tokens = tokens[:self.max_seq_len]\n",
        "        length = len(tokens)\n",
        "        encode_result = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        padding = [0] * (self.max_seq_len - len(encode_result))\n",
        "        encode_result += padding\n",
        "        return encode_result, length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        对无标签数据做数据增强与否\n",
        "        :param idx:  int数字，迭代时的索引\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        #如果做数据增强\n",
        "        if self.train_aug:\n",
        "            # 数据增强的文本augtext_u和augtext_v， 原始文本ori_text\n",
        "            augtext_u, ori_text = self.augment(self.text[idx])\n",
        "            encode_result_u, length_u = self.get_tokenized(augtext_u)\n",
        "            encode_result_ori, length_ori = self.get_tokenized(ori_text)\n",
        "            return ((torch.tensor(encode_result_u), torch.tensor(encode_result_ori)), (length_u,length_ori))\n",
        "        #如果不做数据增强\n",
        "        else:\n",
        "            text = self.text[idx]\n",
        "            encode_result, length = self.get_tokenized(text)\n",
        "            return (torch.tensor(encode_result), length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i_ewZEpoAZW"
      },
      "source": [
        "class loader_labeled(Dataset):\n",
        "    def __init__(self, dataset_text, dataset_label, tokenizer, max_seq_len, aug=False):\n",
        "        \"\"\"\n",
        "        # 有标签数据的loader, trans_dist 是存储翻译后的结果，\n",
        "        :param dataset_text:  文本array\n",
        "        :param dataset_label:  对应的标签array\n",
        "        :param tokenizer:  使用的tokenizer对象\n",
        "        :param max_seq_len:  最大序列长度\n",
        "        :param aug:  是否使用数据增强\n",
        "        \"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "        self.text = dataset_text\n",
        "        self.labels = dataset_label\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.aug = aug\n",
        "        self.trans_dist = {}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def augment(self, text):\n",
        "        \"\"\"\n",
        "        数据增强, 翻译成英文，在翻译回中文\n",
        "        :param text: 单个文档的文本\n",
        "        :return:  新的列表，列表里面是生成后的文本\n",
        "        \"\"\"\n",
        "        TranslatorF= GoogleTranslator(source='auto', target='en')\n",
        "        TranslatorI= GoogleTranslator(source='auto', target='chinese (simplified)')\n",
        "        if text not in self.trans_dist:\n",
        "            text1 = TranslatorF.translate(text=text)\n",
        "            text2 = TranslatorI.translate(text=text1)\n",
        "            self.trans_dist[text] = text2\n",
        "        return self.trans_dist[text]\n",
        "\n",
        "    def get_tokenized(self, text):\n",
        "        \"\"\"\n",
        "        对单个文档的文本text做tokenizer\n",
        "        :param text: 纯文本内容\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        tokens = self.tokenizer.tokenize(text)\n",
        "        #若果大于最大长度，那么截断\n",
        "        if len(tokens) > self.max_seq_len:\n",
        "            tokens = tokens[:self.max_seq_len]\n",
        "        #获取最后的长度\n",
        "        length = len(tokens)\n",
        "        # 把token 转换成id， encode_result是转换成id后的数字列表\n",
        "        encode_result = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        #如果小于最长长度，那么做padding\n",
        "        padding = [0] * (self.max_seq_len - len(encode_result))\n",
        "        #padding 0加到末尾\n",
        "        encode_result += padding\n",
        "\n",
        "        return encode_result, length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        :param idx: 迭代是的索引，int\n",
        "        :return: 如果数据增强： 原始文本encode后的结果（做了padding），数据增强生成的文本encode后结果，各自对应的labels和未padding时的文本长度\n",
        "        \"\"\"\n",
        "        if self.aug:\n",
        "            text = self.text[idx]\n",
        "            text_aug = self.augment(text)\n",
        "            #对原始文本和生成的文本都进行encode， text_result是encode后的id列表，text_length是文本的实际长度\n",
        "            text_result, text_length = self.get_tokenized(text)\n",
        "            text_result2, text_length2 = self.get_tokenized(text_aug)\n",
        "            print(\"augment data with google translate\")\n",
        "            return ((torch.tensor(text_result), torch.tensor(text_result2)), (self.labels[idx], self.labels[idx]), (text_length, text_length2))\n",
        "        else:\n",
        "          \n",
        "            text = self.text[idx]\n",
        "            encode_result, length = self.get_tokenized(text)\n",
        "            #如果不做数据增强，只返回原始文本encode结果，对应label，和原始文本的长度\n",
        "            return (torch.tensor(encode_result), self.labels[idx], length)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR3ge_c0owGh"
      },
      "source": [
        "class argment(object):\n",
        "    def __init__(self,input_dict):\n",
        "        self.epochs=input_dict[\"epochs\"]\n",
        "        self.batch_size=input_dict[\"batch_size\"]\n",
        "        self.batch_size_u=input_dict[\"batch_szie_u\"]\n",
        "        self.lrmain=input_dict[\"lrmax\"]\n",
        "        self.lrlast=input_dict[\"lrlast\"]\n",
        "        self.gpu=input_dict[\"gpu\"]\n",
        "        self.n_labeled=input_dict[\"n_laneled\"]\n",
        "        self.un_labeled=input_dict[\"un_labeled\"]\n",
        "        self.val_iteration=input_dict[\"val_iteration\"]\n",
        "        self.mix_option=input_dict[\"mix_option\"]\n",
        "        self.mix_method=input_dict[\"mix_method\"]\n",
        "        self.separate_mix=input_dict[\"separate_mix\"]\n",
        "        self.co=input_dict[\"co\"]\n",
        "        self.train_aug=input_dict[\"train_ug\"]\n",
        "        self.model=input_dict[\"model\"]\n",
        "        self.data_path=input_dict[\"data_path\"]\n",
        "        self.mix_layers_set=input_dict[\"mix_layers_set\"]\n",
        "        self.alpha=input_dict[\"alpha\"]\n",
        "        self.lambda_u=input_dict[\"lambda_u\"]\n",
        "        self.T=input_dict[\"T\"]\n",
        "        self.temp_change=input_dict[\"temp_change\"]\n",
        "        self.margin=input_dict[\"margin\"]\n",
        "        self.lambda_u_hinge=input_dict[\"lambda_u_hinge\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCkw9K0lpxis"
      },
      "source": [
        "train_prameters={\n",
        "    \"epochs\":15,\n",
        "    \"batch_size\":4,\n",
        "    \"batch_szie_u\":24,\n",
        "    \"lrmax\":0.00001,\n",
        "    \"lrlast\":0.001,\n",
        "    \"gpu\":1,\n",
        "    \"n_laneled\":20,\n",
        "    \"un_labeled\":5000,\n",
        "    \"val_iteration\":200,\n",
        "    \"mix_option\":True,\n",
        "    \"mix_method\":0,\n",
        "    \"separate_mix\":False,\n",
        "    \"co\":False,\n",
        "    \"train_ug\":False,\n",
        "    \"model\":'bert-base-chinese',\n",
        "    \"data_path\":\"../data/NLP\",\n",
        "    \"mix_layers_set\":[0, 1, 2, 3],\n",
        "    \"alpha\":0.75,\n",
        "    \"lambda_u\":1,\n",
        "    \"T\":0.5,\n",
        "    \"temp_change\":1000000,\n",
        "    \"margin\":0.7,\n",
        "    \"lambda_u_hinge\":0\n",
        "}\n",
        "args=argment(train_prameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-0_5Czrpz-r"
      },
      "source": [
        "class SemiLoss(object):\n",
        "    def __call__(self, outputs_x, targets_x, outputs_u, targets_u, outputs_u_2, epoch, mixed=1):\n",
        "        \"\"\"\n",
        "        半监督损失函数\n",
        "        :param outputs_x: 模型输出的x\n",
        "        :param targets_x: 真实的x\n",
        "        :param outputs_u: 模型输出的无标签的x\n",
        "        :param targets_u:  真实的无标签的x\n",
        "        :param outputs_u_2: 模型输出的无标签x_2\n",
        "        :param epoch:  迭代次数\n",
        "        :param mixed: 是否是混合过的输出\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if args.mix_method == 0 or args.mix_method == 1:\n",
        "            #有监督的x的损失\n",
        "            Lx = - \\\n",
        "                torch.mean(torch.sum(F.log_softmax(\n",
        "                    outputs_x, dim=1) * targets_x, dim=1))\n",
        "            #无监督的x输出的概率值\n",
        "            probs_u = torch.softmax(outputs_u, dim=1)\n",
        "            #论文中公式显示的kl散度, batch mean 批次均值作为统计计算KL散度\n",
        "            Lu = F.kl_div(probs_u.log(), targets_u, None, None, 'batchmean')\n",
        "            #计算hinge Loss 折页损失 max(0,1-(wTxi +b)yi)\n",
        "            Lu2 = torch.mean(torch.clamp(torch.sum(-F.softmax(outputs_u, dim=1)\n",
        "                                                   * F.log_softmax(outputs_u, dim=1), dim=1) - args.margin, min=0))\n",
        "\n",
        "        elif args.mix_method == 2:\n",
        "            if mixed == 0:\n",
        "                Lx = - \\\n",
        "                    torch.mean(torch.sum(F.logsigmoid(\n",
        "                        outputs_x) * targets_x, dim=1))\n",
        "\n",
        "                probs_u = torch.softmax(outputs_u, dim=1)\n",
        "\n",
        "                Lu = F.kl_div(probs_u.log(), targets_u,\n",
        "                              None, None, 'batchmean')\n",
        "\n",
        "                Lu2 = torch.mean(torch.clamp(args.margin - torch.sum(\n",
        "                    F.softmax(outputs_u_2, dim=1) * F.softmax(outputs_u_2, dim=1), dim=1), min=0))\n",
        "            else:\n",
        "                Lx = - \\\n",
        "                    torch.mean(torch.sum(F.log_softmax(\n",
        "                        outputs_x, dim=1) * targets_x, dim=1))\n",
        "\n",
        "                probs_u = torch.softmax(outputs_u, dim=1)\n",
        "                Lu = F.kl_div(probs_u.log(), targets_u,\n",
        "                              None, None, 'batchmean')\n",
        "\n",
        "                Lu2 = torch.mean(torch.clamp(args.margin - torch.sum(\n",
        "                    F.softmax(outputs_u, dim=1) * F.softmax(outputs_u, dim=1), dim=1), min=0))\n",
        "\n",
        "        return Lx, Lu, args.lambda_u * linear_rampup(epoch), Lu2, args.lambda_u_hinge * linear_rampup(epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9X_oM9zp3a6"
      },
      "source": [
        "def linear_rampup(current, rampup_length=args.epochs):\n",
        "    if rampup_length == 0:\n",
        "        return 1.0\n",
        "    else:\n",
        "        current = np.clip(current / rampup_length, 0.0, 1.0)\n",
        "        return float(current)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkmVMWKpqCLl"
      },
      "source": [
        "#only for valid \n",
        "def validate(valloader, model, criterion, epoch, mode):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        loss_total = 0\n",
        "        total_sample = 0\n",
        "        acc_total = 0\n",
        "        correct = 0\n",
        "\n",
        "        for batch_idx, (inputs, targets, length) in enumerate(valloader):\n",
        "            if n_gpu !=0:\n",
        "                inputs, targets = inputs.cuda(), targets.cuda(non_blocking=True)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            if batch_idx == 0:\n",
        "                print(\"Sample some true labeles and predicted labels\")\n",
        "                print(predicted[:20])\n",
        "                print(targets[:20])\n",
        "\n",
        "            correct += (np.array(predicted.cpu()) ==\n",
        "                        np.array(targets.cpu())).sum()\n",
        "            loss_total += loss.item() * inputs.shape[0]\n",
        "            total_sample += inputs.shape[0]\n",
        "\n",
        "        acc_total = correct/total_sample\n",
        "        loss_total = loss_total/total_sample\n",
        "\n",
        "    return loss_total, acc_total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4TBHudXqO4a"
      },
      "source": [
        "def train(labeled_trainloader, unlabeled_trainloader, model, optimizer, scheduler, criterion, epoch, n_labels, train_aug=False):\n",
        "    \"\"\"\n",
        "    :param labeled_trainloader: 有标签数据\n",
        "    :param unlabeled_trainloader: 无标签数据\n",
        "    :param model:  Mixtext 模型\n",
        "    :param optimizer: 优化器\n",
        "    :param scheduler: 动态更新学习率\n",
        "    :param criterion: 损失函数\n",
        "    :param epoch:\n",
        "    :param n_labels: 标签类别数量\n",
        "    :param train_aug: 是否使用数据增强\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    labeled_train_iter = iter(labeled_trainloader)\n",
        "    unlabeled_train_iter = iter(unlabeled_trainloader)\n",
        "    model.train()\n",
        "    #设定更改温度T的条件\n",
        "    global total_steps\n",
        "    global flag\n",
        "    if flag == 0 and total_steps > args.temp_change:\n",
        "        print('改变sharpen function的温度选项')\n",
        "        args.T = 0.9\n",
        "        flag = 1\n",
        "\n",
        "    for batch_idx in range(args.val_iteration):\n",
        "\n",
        "        total_steps += 1\n",
        "        #如果训练集不做数据增强\n",
        "        if not train_aug:\n",
        "            inputs_x, targets_x, inputs_x_length = labeled_train_iter.next()\n",
        "        #训练集做数据增强\n",
        "        else:\n",
        "            (inputs_x, inputs_x_aug), (targets_x, _), (inputs_x_length, inputs_x_length_aug) = labeled_train_iter.next()\n",
        "            (inputs_u,  inputs_ori), (length_u,  length_ori) = unlabeled_train_iter.next()\n",
        "        batch_size = inputs_x.size(0)\n",
        "        #原始输入句子的批次\n",
        "        batch_size_2 = inputs_ori.size(0)\n",
        "        #targets_x 做成one_hot编码\n",
        "        targets_x = torch.zeros(batch_size, n_labels).scatter_(1, targets_x.view(-1, 1), 1)\n",
        "        if n_gpu != 0:\n",
        "            inputs_x, targets_x = inputs_x.cuda(), targets_x.cuda(non_blocking=True)\n",
        "            inputs_u = inputs_u.cuda()\n",
        "            inputs_ori = inputs_ori.cuda()\n",
        "\n",
        "        mask = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # 对无标签数据预测标签, outputs_u是对增强的无标签数据预测，预测出的类别置信度, 首先猜测无标签数据的低熵标签\n",
        "            outputs_u = model(inputs_u)\n",
        "            outputs_ori = model(inputs_ori)\n",
        "\n",
        "            # 根据不同数据翻译后的质量，给与不同的权重\n",
        "            # For AG News: German: 1, Russian: 0, ori: 1\n",
        "            # For DBPedia: German: 1, Russian: 1, ori: 1\n",
        "            # For IMDB: German: 0, Russian: 0, ori: 1\n",
        "            # For Yahoo Answers: German: 1, Russian: 0, ori: 1 / German: 0, Russian: 0, ori: 1\n",
        "            p = (0 * torch.softmax(outputs_u, dim=1)  + 1 * torch.softmax(outputs_ori, dim=1)) / (1)\n",
        "            # sharpen 计算，p的n次方, 如果T是0.5，那么pt就是p的平方值\n",
        "            pt = p**(1/args.T)\n",
        "            # targets_u 是求一个百分比,是论文中标签猜测算法部分\n",
        "            targets_u = pt / pt.sum(dim=1, keepdim=True)\n",
        "            targets_u = targets_u.detach()\n",
        "        #是否使用mix, 1表示已经mix，是一个flag\n",
        "        mixed = 1\n",
        "\n",
        "        # 训练时是否随机选择在mix和unmix之间\n",
        "        if args.co:\n",
        "            mix_ = np.random.choice([0, 1], 1)[0]\n",
        "        else:\n",
        "            mix_ = 1\n",
        "        # 如果使用mix，设置beta分布参数 beta分布的alpha参数 lbeta, lbeta是一个浮点数, beta分布的参数alpha,beta, Dirichlet 分布是由 Beta 分布推广而来的\n",
        "        if mix_ == 1:\n",
        "            lbeta = np.random.beta(args.alpha, args.alpha)\n",
        "            if args.separate_mix:\n",
        "                lbeta = lbeta\n",
        "            else:\n",
        "                lbeta = max(lbeta, 1-lbeta)\n",
        "        else:\n",
        "            lbeta = 1\n",
        "        #选择哪一层进行mix_layer, 随机选择一层，减去1是为了和列表索引相对应,例如选择bert的第11层\n",
        "        mix_layer = np.random.choice(args.mix_layers_set, 1)[0]\n",
        "        mix_layer = mix_layer - 1\n",
        "\n",
        "        #如果不使用数据增强\n",
        "        if not train_aug:\n",
        "            all_inputs = torch.cat(\n",
        "                [inputs_x, inputs_u, inputs_ori, inputs_ori], dim=0)\n",
        "\n",
        "            all_lengths = torch.cat(\n",
        "                [inputs_x_length, length_u, length_ori, length_ori], dim=0)\n",
        "\n",
        "            all_targets = torch.cat(\n",
        "                [targets_x, targets_u, targets_u, targets_u, targets_u], dim=0)\n",
        "\n",
        "        #如果使用数据增强，拼接所有输入，长度和标签（无标签数据预测出来的标签)\n",
        "        else:\n",
        "            all_inputs = torch.cat(\n",
        "                [inputs_x, inputs_x_aug, inputs_u, inputs_ori], dim=0)\n",
        "            all_lengths = torch.cat(\n",
        "                [inputs_x_length, inputs_x_length, length_u, length_ori], dim=0)\n",
        "            all_targets = torch.cat(\n",
        "                [targets_x, targets_x, targets_u, targets_u], dim=0)\n",
        "        #分别进行mix, 是使用batch_size个还是全部，是从batch_size 获取，还是从全部数据获取\n",
        "        if args.separate_mix:\n",
        "            #随机打乱函数randperm，获取索引，就是把无标签，有标签和数据增强的数据随机抽取出来进行训练\n",
        "            idx1 = torch.randperm(batch_size)\n",
        "            idx2 = torch.randperm(all_inputs.size(0) - batch_size) + batch_size\n",
        "            idx = torch.cat([idx1, idx2], dim=0)\n",
        "\n",
        "        else:\n",
        "            idx1 = torch.randperm(all_inputs.size(0) - batch_size_2)\n",
        "            idx2 = torch.arange(batch_size_2) + all_inputs.size(0) - batch_size_2\n",
        "            idx = torch.cat([idx1, idx2], dim=0)\n",
        "        #input_a是所有输入，input_b是抽取的部分输入,input和target都是embedding后的向量，length_a,length_b是原始的seq_length,未加padding时候的\n",
        "        input_a, input_b = all_inputs, all_inputs[idx]\n",
        "        target_a, target_b = all_targets, all_targets[idx]\n",
        "        length_a, length_b = all_lengths, all_lengths[idx]\n",
        "\n",
        "        if args.mix_method == 0:\n",
        "            # Mix句子的隐藏向量,input_a是所有输入，input_b是随机抽取的输入\n",
        "            logits = model(input_a, input_b, lbeta, mix_layer)\n",
        "            #对target也使用Mixup混合，公式是论文上的公式\n",
        "            mixed_target = lbeta * target_a + (1 - lbeta) * target_b\n",
        "        elif args.mix_method == 1:\n",
        "            # 拼接2个训练句子的片段，  片段的选择根据beta分布lbeta\n",
        "            # 例如: \"I love you so much\" 和 \"He likes NLP\" 可能混合成 \"He likes NLP so much\".\n",
        "            # 对应的labels也会根据系数被混合\n",
        "            mixed_input = []\n",
        "            if lbeta != 1:\n",
        "                for i in range(input_a.size(0)):\n",
        "                    length1 = math.floor(int(length_a[i]) * lbeta)\n",
        "                    idx1 = torch.randperm(int(length_a[i]) - length1 + 1)[0]\n",
        "                    length2 = math.ceil(int(length_b[i]) * (1-lbeta))\n",
        "                    if length1 + length2 > 256:\n",
        "                        length2 = 256-length1 - 1\n",
        "                    idx2 = torch.randperm(int(length_b[i]) - length2 + 1)[0]\n",
        "                    try:\n",
        "                        if n_gpu !=0:\n",
        "                            mixed_input.append(torch.cat((input_a[i][idx1: idx1 + length1], torch.tensor([102]).cuda(), input_b[i][idx2:idx2 + length2], torch.tensor([0]*(256-1-length1-length2)).cuda()), dim=0).unsqueeze(0))\n",
        "                        else:\n",
        "                            mixed_input.append(torch.cat((input_a[i][idx1: idx1 + length1], torch.tensor([102]), input_b[i][idx2:idx2 + length2], torch.tensor([0]*(256-1-length1-length2))), dim=0).unsqueeze(0))\n",
        "                    except:\n",
        "                        print(256 - 1 - length1 - length2,idx2, length2, idx1, length1)\n",
        "\n",
        "                mixed_input = torch.cat(mixed_input, dim=0)\n",
        "\n",
        "            else:\n",
        "                mixed_input = input_a\n",
        "\n",
        "            logits = model(mixed_input)\n",
        "            mixed_target = lbeta * target_a + (1 - lbeta) * target_b\n",
        "\n",
        "        elif args.mix_method == 2:\n",
        "            # 拼接2个句子\n",
        "            # 对应的label是平均值\n",
        "            if lbeta == 1:\n",
        "                mixed_input = []\n",
        "                for i in range(input_a.size(0)):\n",
        "                    if n_gpu != 0:\n",
        "                        mixed_input.append(torch.cat((input_a[i][:length_a[i]], torch.tensor([102]).cuda(), input_b[i][:length_b[i]], torch.tensor([0]*(512-1-int(length_a[i])-int(length_b[i]))).cuda()), dim=0).unsqueeze(0))\n",
        "                    else:\n",
        "                        mixed_input.append(torch.cat((input_a[i][:length_a[i]], torch.tensor([102]), input_b[i][:length_b[i]], torch.tensor([0]*(512-1-int(length_a[i])-int(length_b[i])))), dim=0).unsqueeze(0))\n",
        "                mixed_input = torch.cat(mixed_input, dim=0)\n",
        "                logits = model(mixed_input, sent_size=512)\n",
        "\n",
        "                #mixed_target = torch.clamp(target_a + target_b, max = 1)\n",
        "                mixed = 0\n",
        "                mixed_target = (target_a + target_b)/2\n",
        "            else:\n",
        "                mixed_input = input_a\n",
        "                mixed_target = target_a\n",
        "                logits = model(mixed_input, sent_size=256)\n",
        "                mixed = 1\n",
        "        #使用SemiLoss计算损失\n",
        "        Lx, Lu, w, Lu2, w2 = criterion(logits[:batch_size], mixed_target[:batch_size], logits[batch_size:-batch_size_2],\n",
        "                                       mixed_target[batch_size:-batch_size_2], logits[-batch_size_2:], epoch+batch_idx/args.val_iteration, mixed)\n",
        "        #如果使用mix\n",
        "        if mix_ == 1:\n",
        "            loss = Lx + w * Lu\n",
        "        else:\n",
        "            loss = Lx + w * Lu + w2 * Lu2\n",
        "\n",
        "        #max_grad_norm = 1.0\n",
        "        # 梯度裁剪\n",
        "        #torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "\n",
        "        if batch_idx % 1000 == 0:\n",
        "            print(\"epoch {}, step {}, loss {}, Lx {}, Lu {}, Lu2 {}\".format(\n",
        "                epoch, batch_idx, loss.item(), Lx.item(), Lu.item(), Lu2.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc6GvLEtZTE3"
      },
      "source": [
        "def train(labeled_trainloader, unlabeled_trainloader, model, optimizer, scheduler, criterion, epoch, n_labels, max_seq_len=256,train_aug=False):\n",
        "    \"\"\"\n",
        "    :param labeled_trainloader: 有标签数据\n",
        "    :param unlabeled_trainloader: 无标签数据\n",
        "    :param model:  Mixtext 模型\n",
        "    :param optimizer: 优化器\n",
        "    :param scheduler: 动态更新学习率\n",
        "    :param criterion: 损失函数\n",
        "    :param epoch:\n",
        "    :param n_labels: 标签类别数量\n",
        "    :param train_aug: 是否使用数据增强\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    labeled_train_iter = iter(labeled_trainloader)\n",
        "    unlabeled_train_iter = iter(unlabeled_trainloader)\n",
        "    model.train()\n",
        "    #设定更改温度T的条件\n",
        "    global total_steps\n",
        "    global flag\n",
        "    if flag == 0 and total_steps > args.temp_change:\n",
        "        print('改变sharpen function的温度选项')\n",
        "        args.T = 0.9\n",
        "        flag = 1\n",
        "\n",
        "\n",
        "    for batch_idx in range(args.val_iteration):\n",
        "\n",
        "        total_steps += 1\n",
        "        #如果训练集不做数据增强\n",
        "        if not train_aug:\n",
        "            inputs_x, targets_x, inputs_x_length = labeled_train_iter.next()\n",
        "            inputs_ori,length_ori= unlabeled_train_iter.next()\n",
        "        #训练集做数据增强\n",
        "        else:\n",
        "            (inputs_x, inputs_x_aug), (targets_x, _), (inputs_x_length, inputs_x_length_aug) = labeled_train_iter.next()\n",
        "            (inputs_u,  inputs_ori), (length_u,  length_ori) = unlabeled_train_iter.next()\n",
        "        batch_size = inputs_x.size(0)\n",
        "        #原始输入句子的批次\n",
        "        batch_size_2 = inputs_ori.size(0)\n",
        "        #targets_x 做成one_hot编码\n",
        "        targets_x = torch.zeros(batch_size, n_labels).scatter_(1, targets_x.view(-1, 1), 1)\n",
        "        if n_gpu != 0:\n",
        "            inputs_x, targets_x = inputs_x.cuda(), targets_x.cuda(non_blocking=True)\n",
        "            inputs_ori = inputs_ori.cuda()\n",
        "            if train_aug:\n",
        "              inputs_u = inputs_u.cuda()\n",
        "\n",
        "        mask = []\n",
        "        with torch.no_grad():\n",
        "            # 对无标签数据预测标签, outputs_u是对增强的无标签数据预测，预测出的类别置信度, 首先猜测无标签数据的低熵标签\n",
        "            if train_aug:\n",
        "              outputs_u = model(inputs_u)\n",
        "            outputs_ori = model(inputs_ori)\n",
        "\n",
        "            # 根据不同数据翻译后的质量，给与不同的权重\n",
        "            # For AG News: German: 1, Russian: 0, ori: 1\n",
        "            # For DBPedia: German: 1, Russian: 1, ori: 1\n",
        "            # For IMDB: German: 0, Russian: 0, ori: 1\n",
        "            # For Yahoo Answers: German: 1, Russian: 0, ori: 1 / German: 0, Russian: 0, ori: 1\n",
        "            if train_aug:\n",
        "              p = (0 * torch.softmax(outputs_u, dim=1)  + 1 * torch.softmax(outputs_ori, dim=1)) / (1)\n",
        "            else:\n",
        "              p=1 * torch.softmax(outputs_ori, dim=1) / (1)\n",
        "            # sharpen 计算，p的n次方, 如果T是0.5，那么pt就是p的平方值\n",
        "            pt = p**(1/args.T)\n",
        "            # targets_u 是求一个百分比,是论文中标签猜测算法部分\n",
        "            targets_u = pt / pt.sum(dim=1, keepdim=True)\n",
        "            targets_u = targets_u.detach()\n",
        "        #是否使用mix, 1表示已经mix，是一个flag\n",
        "        mixed = 1\n",
        "\n",
        "        # 训练时是否随机选择在mix和unmix之间\n",
        "        if args.co:\n",
        "            mix_ = np.random.choice([0, 1], 1)[0]\n",
        "        else:\n",
        "            mix_ = 1\n",
        "        # 如果使用mix，设置beta分布参数 beta分布的alpha参数 lbeta, lbeta是一个浮点数, beta分布的参数alpha,beta, Dirichlet 分布是由 Beta 分布推广而来的\n",
        "        if mix_ == 1:\n",
        "            lbeta = np.random.beta(args.alpha, args.alpha)\n",
        "            if args.separate_mix:\n",
        "                lbeta = lbeta\n",
        "            else:\n",
        "                lbeta = max(lbeta, 1-lbeta)\n",
        "        else:\n",
        "            lbeta = 1\n",
        "        #选择哪一层进行mix_layer, 随机选择一层，减去1是为了和列表索引相对应,例如选择bert的第11层\n",
        "        mix_layer = np.random.choice(args.mix_layers_set, 1)[0]\n",
        "        mix_layer = mix_layer - 1\n",
        "\n",
        "        #如果不使用数据增强\n",
        "        if not train_aug:\n",
        "            all_inputs = torch.cat(\n",
        "                [inputs_x, inputs_ori], dim=0)\n",
        "\n",
        "            all_lengths = torch.cat(\n",
        "                [inputs_x_length, length_ori], dim=0)\n",
        "\n",
        "            all_targets = torch.cat(\n",
        "                [targets_x, targets_u], dim=0)\n",
        "\n",
        "        #如果使用数据增强，拼接所有输入，长度和标签（无标签数据预测出来的标签)\n",
        "        else:\n",
        "            all_inputs = torch.cat(\n",
        "                [inputs_x, inputs_x_aug, inputs_u, inputs_ori], dim=0)\n",
        "            all_lengths = torch.cat(\n",
        "                [inputs_x_length, inputs_x_length, length_u, length_ori], dim=0)\n",
        "            all_targets = torch.cat(\n",
        "                [targets_x, targets_x, targets_u, targets_u], dim=0)\n",
        "        #分别进行mix, 是使用batch_size个还是全部，是从batch_size 获取，还是从全部数据获取\n",
        "        if args.separate_mix:\n",
        "            #随机打乱函数randperm，获取索引，就是把无标签，有标签和数据增强的数据随机抽取出来进行训练\n",
        "            idx1 = torch.randperm(batch_size)\n",
        "            idx2 = torch.randperm(all_inputs.size(0) - batch_size) + batch_size\n",
        "            idx = torch.cat([idx1, idx2], dim=0)\n",
        "\n",
        "        else:\n",
        "            idx1 = torch.randperm(all_inputs.size(0) - batch_size_2)\n",
        "            idx2 = torch.arange(batch_size_2) + all_inputs.size(0) - batch_size_2\n",
        "            idx = torch.cat([idx1, idx2], dim=0)\n",
        "        #input_a是所有输入，input_b是抽取的部分输入,input和target都是embedding后的向量，length_a,length_b是原始的seq_length,未加padding时候的\n",
        "        input_a, input_b = all_inputs, all_inputs[idx]\n",
        "        target_a, target_b = all_targets, all_targets[idx]\n",
        "        length_a, length_b = all_lengths, all_lengths[idx]\n",
        "\n",
        "        if args.mix_method == 0:\n",
        "            # Mix句子的隐藏向量,input_a是所有输入，input_b是随机抽取的输入\n",
        "            logits = model(input_a, input_b, lbeta, mix_layer)\n",
        "            #对target也使用Mixup混合，公式是论文上的公式\n",
        "            mixed_target = lbeta * target_a + (1 - lbeta) * target_b\n",
        "        elif args.mix_method == 1:\n",
        "            # 拼接2个训练句子的片段，  片段的选择根据beta分布lbeta\n",
        "            # 例如: \"I love you so much\" 和 \"He likes NLP\" 可能混合成 \"He likes NLP so much\".\n",
        "            # 对应的labels也会根据系数被混合\n",
        "            mixed_input = []\n",
        "            if lbeta != 1:\n",
        "                for i in range(input_a.size(0)):\n",
        "                    length1 = math.floor(int(length_a[i]) * lbeta)\n",
        "                    idx1 = torch.randperm(int(length_a[i]) - length1 + 1)[0]\n",
        "                    length2 = math.ceil(int(length_b[i]) * (1-lbeta))\n",
        "                    if length1 + length2 > max_seq_len:\n",
        "                        length2 = max_seq_len-length1 - 1\n",
        "                    idx2 = torch.randperm(int(length_b[i]) - length2 + 1)[0]\n",
        "                    try:\n",
        "                        if n_gpu !=0:\n",
        "                            mixed_input.append(torch.cat((input_a[i][idx1: idx1 + length1], torch.tensor([102]).cuda(), input_b[i][idx2:idx2 + length2], torch.tensor([0]*(256-1-length1-length2)).cuda()), dim=0).unsqueeze(0))\n",
        "                        else:\n",
        "                            mixed_input.append(torch.cat((input_a[i][idx1: idx1 + length1], torch.tensor([102]), input_b[i][idx2:idx2 + length2], torch.tensor([0]*(256-1-length1-length2))), dim=0).unsqueeze(0))\n",
        "                    except:\n",
        "                        print(max_seq_len - 1 - length1 - length2,idx2, length2, idx1, length1)\n",
        "\n",
        "                mixed_input = torch.cat(mixed_input, dim=0)\n",
        "\n",
        "            else:\n",
        "                mixed_input = input_a\n",
        "\n",
        "            logits = model(mixed_input)\n",
        "            mixed_target = lbeta * target_a + (1 - lbeta) * target_b\n",
        "\n",
        "        elif args.mix_method == 2:\n",
        "            # 拼接2个句子\n",
        "            # 对应的label是平均值\n",
        "            if lbeta == 1:\n",
        "                mixed_input = []\n",
        "                for i in range(input_a.size(0)):\n",
        "                    if n_gpu != 0:\n",
        "                        mixed_input.append(torch.cat((input_a[i][:length_a[i]], torch.tensor([102]).cuda(), input_b[i][:length_b[i]], torch.tensor([0]*(512-1-int(length_a[i])-int(length_b[i]))).cuda()), dim=0).unsqueeze(0))\n",
        "                    else:\n",
        "                        mixed_input.append(torch.cat((input_a[i][:length_a[i]], torch.tensor([102]), input_b[i][:length_b[i]], torch.tensor([0]*(512-1-int(length_a[i])-int(length_b[i])))), dim=0).unsqueeze(0))\n",
        "                mixed_input = torch.cat(mixed_input, dim=0)\n",
        "                logits = model(mixed_input, sent_size=512)\n",
        "\n",
        "                #mixed_target = torch.clamp(target_a + target_b, max = 1)\n",
        "                mixed = 0\n",
        "                mixed_target = (target_a + target_b)/2\n",
        "            else:\n",
        "                mixed_input = input_a\n",
        "                mixed_target = target_a\n",
        "                logits = model(mixed_input, sent_size=max_seq_len)\n",
        "                mixed = 1\n",
        "        #使用SemiLoss计算损失\n",
        "        if not train_aug:\n",
        "          Lx, Lu, w, Lu2, w2 = criterion(logits[:batch_size], mixed_target[:batch_size], logits[-batch_size_2:],\n",
        "                                       mixed_target[-batch_size_2:], logits[-batch_size_2:], epoch+batch_idx/args.val_iteration, mixed)\n",
        "        else:\n",
        "          Lx, Lu, w, Lu2, w2 = criterion(logits[:batch_size], mixed_target[:batch_size], logits[batch_size:-batch_size_2],\n",
        "                                       mixed_target[batch_size:-batch_size_2], logits[-batch_size_2:], epoch+batch_idx/args.val_iteration, mixed)\n",
        "        #如果使用mix\n",
        "        if mix_ == 1:\n",
        "            loss = Lx + w * Lu\n",
        "        else:\n",
        "            loss = Lx + w * Lu + w2 * Lu2\n",
        "        if not train_aug:\n",
        "          loss=Lx + w2 * Lu2 \n",
        "        #max_grad_norm = 1.0\n",
        "        # 梯度裁剪\n",
        "        #torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "\n",
        "        if batch_idx % 1000 == 0:\n",
        "            print(\"epoch {}, step {}, loss {}, Lx {}, Lu {}, Lu2 {}\".format(\n",
        "                epoch, batch_idx, loss.item(), Lx.item(), Lu.item(), Lu2.item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X-IuqfgEX5y"
      },
      "source": [
        "def initial(n_labels,checkpoint_name=\"/content/drive/My Drive/MixText/code/model/my_model.pt\"):\n",
        "  # 定义模型，设置优化器\n",
        "  if n_gpu == 0:\n",
        "        model = MixText(n_labels, args.mix_option, model=args.model)\n",
        "  else:\n",
        "        model = MixText(n_labels, args.mix_option, model=args.model).cuda()\n",
        "\n",
        "  checkpoint=torch.load(checkpoint_name)\n",
        "\n",
        "  model.load_state_dict(checkpoint)\n",
        "  print(\"load model sucess!\")\n",
        "  model = nn.DataParallel(model)\n",
        "  #优化器参数\n",
        "  optimizer = AdamW(\n",
        "        [\n",
        "            {\"params\": model.module.bert.parameters(), \"lr\": args.lrmain},\n",
        "            {\"params\": model.module.linear.parameters(), \"lr\": args.lrlast},\n",
        "        ])\n",
        "  #预热步数\n",
        "  num_warmup_steps = math.floor(50)\n",
        "  num_total_steps = args.val_iteration\n",
        "  #是否动态更新学习率\n",
        "  scheduler = None\n",
        "  #WarmupConstantSchedule(optimizer, warmup_steps=num_warmup_steps)\n",
        "  #训练损失函数，用在训练时\n",
        "  train_criterion = SemiLoss()\n",
        "  #交叉熵损失, 用在验证集和测试集\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  return  model, optimizer,scheduler, train_criterion,criterion "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7HRYvEodTdR"
      },
      "source": [
        "train_prameters={\n",
        "    \"epochs\":15,\n",
        "    \"batch_size\":4,\n",
        "    \"batch_szie_u\":12,\n",
        "    \"lrmax\":0.00001,\n",
        "    \"lrlast\":0.001,\n",
        "    \"gpu\":1,\n",
        "    \"n_laneled\":20,\n",
        "    \"un_labeled\":5000,\n",
        "    \"val_iteration\":100,\n",
        "    \"mix_option\":True,\n",
        "    \"mix_method\":0,\n",
        "    \"separate_mix\":False,\n",
        "    \"co\":False,\n",
        "    \"train_ug\":False,\n",
        "    \"model\":'bert-base-chinese',\n",
        "    \"data_path\":\"../data/NLP2\",\n",
        "    \"mix_layers_set\":[7,9,12],\n",
        "    \"alpha\":0.4,\n",
        "    \"lambda_u\":1,\n",
        "    \"T\":0.5,\n",
        "    \"temp_change\":1000000,\n",
        "    \"margin\":0.7,\n",
        "    \"lambda_u_hinge\":1\n",
        "}\n",
        "args=argment(train_prameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoIs6NUnqh0m",
        "outputId": "a2d0259a-5a10-407c-88a8-d4db322ee225"
      },
      "source": [
        "##GPU相关设置, 设置为0表示不适用gpu\n",
        "##os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "if n_gpu == 0:\n",
        "    print(\"GPU 数量为0，使用CPU\")\n",
        "else:\n",
        "    print(\"可以使用的GPU 数量: \", n_gpu)\n",
        "\n",
        "\n",
        "best_acc = 0\n",
        "total_steps = 0\n",
        "flag = 0\n",
        "print('是否要进行mix: ', args.mix_option)\n",
        "print(\"Mix层集合: \", args.mix_layers_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "可以使用的GPU 数量:  1\n",
            "是否要进行mix:  True\n",
            "Mix层集合:  [7, 9, 12]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbzJjYNviDgg",
        "outputId": "574b4b6d-0ea8-48c5-8b60-f2d164e61def"
      },
      "source": [
        "global best_acc\n",
        "\n",
        "train_labeled_set, train_unlabeled_set, val_set, test_set, n_labels = get_data(\n",
        "        \"../data/NLP2\",10, max_seq_len=256, model='bert-base-chinese', train_aug=False)\n",
        "# 制作loader\n",
        "labeled_trainloader = Data.DataLoader(\n",
        "        dataset=train_labeled_set, batch_size=args.batch_size, shuffle=True)\n",
        "unlabeled_trainloader = Data.DataLoader(\n",
        "        dataset=train_unlabeled_set, batch_size=args.batch_size_u, shuffle=True)\n",
        "val_loader = Data.DataLoader(\n",
        "        dataset=val_set, batch_size=20, shuffle=False)\n",
        "test_loader = Data.DataLoader(\n",
        "        dataset=test_set, batch_size=20, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 109540/109540 [00:00<00:00, 429861.02B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWh2gK1MkE9l"
      },
      "source": [
        "from mixtext import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WghySdYKqs1m",
        "outputId": "29f4333f-359e-4ea8-af08-b149a71c41e5"
      },
      "source": [
        "model, optimizer,scheduler, criterion=initial()\n",
        "test_accs = []\n",
        "#开始训练\n",
        "for epoch in range(args.epochs):\n",
        "        args.train_aug=False\n",
        "        #调用train函数, 给定有标签数据，无标签数据，模型，优化器，损失函数，labels数量，是否数据增强\n",
        "        train(labeled_trainloader, unlabeled_trainloader, model, optimizer,scheduler, train_criterion, epoch, n_labels, 256,args.train_aug)\n",
        "\n",
        "        # scheduler.step()\n",
        "        # _, train_acc = validate(labeled_trainloader, model,  criterion, epoch, mode='Train Stats')\n",
        "        #print(\"epoch {}, train acc {}\".format(epoch, train_acc))\n",
        "\n",
        "        val_loss, val_acc = validate(val_loader, model, criterion, epoch, mode='Valid Stats')\n",
        "\n",
        "        print(\"epoch {}, 验证集准确率 {}, 验证集损失 {}\".format(epoch, val_acc, val_loss))\n",
        "\n",
        "        print('Epoch: ', epoch)\n",
        "        \n",
        "        \n",
        "\n",
        "print(\"完成训练\")\n",
        "print('最好的准去率')\n",
        "print(best_acc)\n",
        "\n",
        "print('测试准确率')\n",
        "print(test_accs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MixText/code/pytransformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0, step 0, loss 0.1959916353225708, Lx 0.1959916353225708, Lu 0.08342268317937851, Lu2 0.13388267159461975\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([3, 0, 1, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "tensor([3, 0, 2, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "epoch 0, 验证集准确率 0.8805748265609514, 验证集损失 0.4327510715682868\n",
            "Epoch:  0\n",
            "epoch 1, step 0, loss 1.4065368175506592, Lx 1.4024966955184937, Lu 0.05828262120485306, Lu2 0.060601331293582916\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([6, 0, 1, 8, 3, 1, 4, 8, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "tensor([3, 0, 2, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "epoch 1, 验证集准确率 0.8795837462834489, 验证集损失 0.4770932705746179\n",
            "Epoch:  1\n",
            "epoch 2, step 0, loss 0.5419385433197021, Lx 0.5403410792350769, Lu 0.08579348027706146, Lu2 0.011981050483882427\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([3, 0, 1, 8, 3, 1, 4, 8, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "tensor([3, 0, 2, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "epoch 2, 验证集准确率 0.8711595639246779, 验证集损失 0.4514750453419208\n",
            "Epoch:  2\n",
            "epoch 3, step 0, loss 0.23466134071350098, Lx 0.20949819684028625, Lu 0.07729872316122055, Lu2 0.125815749168396\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([6, 0, 1, 8, 3, 1, 4, 8, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "tensor([3, 0, 2, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "epoch 3, 验证集准确率 0.8825569871159564, 验证集损失 0.4614553051613958\n",
            "Epoch:  3\n",
            "epoch 4, step 0, loss 1.2351521253585815, Lx 1.220710039138794, Lu 0.06802412122488022, Lu2 0.054157912731170654\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([6, 0, 1, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "tensor([3, 0, 2, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "epoch 4, 验证集准确率 0.877601585728444, 验证集损失 0.4521889209127048\n",
            "Epoch:  4\n",
            "epoch 5, step 0, loss 0.5246790647506714, Lx 0.4919896721839905, Lu 0.08816221356391907, Lu2 0.0980682224035263\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([6, 0, 1, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "tensor([3, 0, 2, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "epoch 5, 验证集准确率 0.8919722497522299, 验证集损失 0.4159723088750754\n",
            "Epoch:  5\n",
            "epoch 6, step 0, loss 1.4645365476608276, Lx 1.4517778158187866, Lu 0.05115547031164169, Lu2 0.03189677745103836\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([3, 0, 1, 8, 3, 1, 4, 8, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "tensor([3, 0, 2, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "epoch 6, 验证集准确率 0.8944499504459861, 验证集损失 0.40089868032719617\n",
            "Epoch:  6\n",
            "epoch 7, step 0, loss 0.8051438331604004, Lx 0.7583135366439819, Lu 0.11632511019706726, Lu2 0.10035061836242676\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([6, 0, 1, 8, 3, 1, 4, 8, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "tensor([3, 0, 2, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "epoch 7, 验证集准确率 0.8875123885034688, 验证集损失 0.43146443851402894\n",
            "Epoch:  7\n",
            "epoch 8, step 0, loss 1.1600602865219116, Lx 1.1406546831130981, Lu 0.06607640534639359, Lu2 0.036385610699653625\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([3, 0, 1, 8, 3, 1, 4, 8, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "tensor([3, 0, 2, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "epoch 8, 验证集准确率 0.8994053518334986, 验证集损失 0.3960543706112267\n",
            "Epoch:  8\n",
            "epoch 9, step 0, loss 0.05557473376393318, Lx 0.043715767562389374, Lu 0.07733764499425888, Lu2 0.019764944911003113\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([3, 0, 1, 8, 3, 1, 4, 8, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "tensor([3, 0, 2, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "epoch 9, 验证集准确率 0.8909811694747275, 验证集损失 0.4217876375489476\n",
            "Epoch:  9\n",
            "epoch 10, step 0, loss 0.09252424538135529, Lx 0.09252424538135529, Lu 0.056894700974226, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([6, 0, 1, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "tensor([3, 0, 2, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "epoch 10, 验证集准确率 0.8825569871159564, 验证集损失 0.43921344705863796\n",
            "Epoch:  10\n",
            "epoch 11, step 0, loss 1.2794839143753052, Lx 1.2794839143753052, Lu 0.03949173167347908, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([6, 0, 1, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "tensor([3, 0, 2, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "epoch 11, 验证集准确率 0.8855302279484638, 验证集损失 0.4384306402520689\n",
            "Epoch:  11\n",
            "epoch 12, step 0, loss 1.0000534057617188, Lx 0.9720825552940369, Lu 0.09400682896375656, Lu2 0.03496357426047325\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([6, 0, 1, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "tensor([3, 0, 2, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "epoch 12, 验证集准确率 0.8830525272547076, 验证集损失 0.4697457789355747\n",
            "Epoch:  12\n",
            "epoch 13, step 0, loss 0.07671920210123062, Lx 0.07136966288089752, Lu 0.07214013487100601, Lu2 0.006172542925924063\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([6, 0, 1, 8, 3, 1, 4, 8, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "tensor([3, 0, 2, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "epoch 13, 验证集准确率 0.8790882061446977, 验证集损失 0.5150909784247192\n",
            "Epoch:  13\n",
            "epoch 14, step 0, loss 1.4012430906295776, Lx 1.3910237550735474, Lu 0.055610328912734985, Lu2 0.010949349030852318\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([3, 0, 1, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 0],\n",
            "       device='cuda:0')\n",
            "tensor([3, 0, 2, 8, 3, 1, 4, 9, 3, 4, 0, 7, 6, 2, 0, 1, 0, 2, 4, 6],\n",
            "       device='cuda:0')\n",
            "epoch 14, 验证集准确率 0.8810703666997026, 验证集损失 0.49488993709015305\n",
            "Epoch:  14\n",
            "完成训练\n",
            "最好的准去率\n",
            "0\n",
            "测试准确率\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFPBvxFvqRPK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "97458b15-1186-4e69-aaf7-7fc43c1280ea"
      },
      "source": [
        "torch.save(model.module.state_dict(), \"/content/drive/My Drive/MixText/code/model/my_model3.pt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-25143491a976>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/My Drive/MixText/code/model/my_model9.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrFTxGSA1-EN"
      },
      "source": [
        "## make a predict \n",
        "model.eval()\n",
        "outputs=[]\n",
        "test_loader = Data.DataLoader(\n",
        "        dataset=test_set, batch_size=30, shuffle=False)\n",
        "for batch_idx, (inputs, length) in enumerate(test_loader):\n",
        "            if n_gpu !=0:\n",
        "                inputs = inputs.cuda()\n",
        "            outputs.extend(model(inputs).detach().cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yxy8FOWRfhu",
        "outputId": "0d7df8d9-fe7c-46ef-9802-5db87f4affb4"
      },
      "source": [
        "torch.max(torch.tensor(outputs), 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(values=tensor([5.0224, 6.1656, 5.1617,  ..., 6.2510, 5.2215, 5.1332]), indices=tensor([7, 9, 2,  ..., 9, 3, 7]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqxCxA_S3TqL"
      },
      "source": [
        "test_df=pd.read_csv(\"../data/NLP2/test_df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj_LfiznT2Uk"
      },
      "source": [
        "train_df=pd.read_csv(\"../data/NLP2/train_valid.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1Yuaojh58EP"
      },
      "source": [
        "_,test_df[\"num_label\"]=torch.max(torch.tensor(outputs), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8NJgtpt3510"
      },
      "source": [
        "def name2label_conv(data):\n",
        "    name2label={\n",
        "        \"财经\":0,\"房产\":1,\"家居\":2,\"教育\":3,\"科技\":4,\"时尚\":5,\"时政\":6,\"游戏\":7,\"娱乐\":8,\"体育\":9\n",
        "    }\n",
        "    data[\"num_label\"]=data[\"class_label\"].apply(lambda x: name2label[x])\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKM3zq_P4H8r"
      },
      "source": [
        "def label2name_conv(data):\n",
        "    label2name={0: '财经',\n",
        "     1: '房产',\n",
        "     2: '家居',\n",
        "     3: '教育',\n",
        "     4: '科技',\n",
        "     5: '时尚',\n",
        "     6: '时政',\n",
        "     7: '游戏',\n",
        "     8: '娱乐',\n",
        "     9: '体育'}\n",
        "    data[\"class_label\"]=data[\"num_label\"].apply(lambda x: label2name[x])\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuKblrLU4RLO"
      },
      "source": [
        "def label2level_conv(data):\n",
        "    level={\"财经\":\"高风险\",\n",
        "           \"房产\":\"中风险\",\n",
        "           \"家居\":\"可公开\",\n",
        "           \"教育\":\"低风险\",\n",
        "           \"科技\":\"中风险\",\n",
        "           \"时尚\":\"低风险\",\n",
        "           \"时政\":\"高风险\",\n",
        "           \"游戏\":\"低风险\",\n",
        "           \"娱乐\":\"可公开\",\n",
        "           \"体育\":\"可公开\"}\n",
        "    data[\"rank_label\"]=data[\"class_label\"].apply(lambda x: level[x])\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-9ReNAE4Vzw"
      },
      "source": [
        "def submit(data,filename):\n",
        "    data=label2name_conv(data)\n",
        "    data=label2level_conv(data)\n",
        "    data=data[[\"id\",\"class_label\",\"rank_label\"]]\n",
        "    data.to_csv(filename,index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMgFf9xb9PN5"
      },
      "source": [
        "train_df.iloc[1674][\"content\"]\n",
        "#1674 ->游戏 可能部分添加错误的标签造成了当前的错误分类"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo-AzIh64dWH"
      },
      "source": [
        "submit(test_df,\"mixText.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4txAI7V8fg7"
      },
      "source": [
        "## 自监督训练 \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSjrzekOC916",
        "outputId": "ffae1c39-b41a-4d79-e44d-1293d90b7402"
      },
      "source": [
        "model, optimizer,scheduler, train_criterion,criterion=initial( 10,\"/content/drive/My Drive/MixText/code/model/self_train_model9.pt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 624/624 [00:00<00:00, 170927.75B/s]\n",
            "100%|██████████| 411577189/411577189 [00:12<00:00, 31938314.40B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "load model sucess!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO068XlMbdOv",
        "outputId": "1c5801cf-7bdb-4ad2-a85b-d342809c7534"
      },
      "source": [
        "## Make predict\n",
        "def text_filter(sentence: str) -> str:\n",
        "        \"\"\"\n",
        "        过滤掉非汉字和标点符号和非数字\n",
        "        :param sentence:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        line = sentence.replace('\\n', '。')\n",
        "        # 过滤掉非汉字和标点符号和非数字\n",
        "        linelist = [word for word in line if\n",
        "                    word >= u'\\u4e00' and word <= u'\\u9fa5' or word in ['，', '。', '？', '！',\n",
        "                                                                        '：'] or word.isdigit()]\n",
        "        return ''.join(linelist)\n",
        "def fliter_data(data):\n",
        "      data['content']=data['content'].astype(str)\n",
        "      data[\"text\"]=data[\"content\"].apply(lambda x:text_filter(x))\n",
        "      return data \n",
        "\n",
        "test_df=pd.read_csv(\"../data/NLP2/0test_df.csv\")\n",
        "test_df=fliter_data(test_df)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
        "test_set = loader_unlabeled(list(test_df[\"text\"]),tokenizer, max_seq_len=256, train_aug=False)\n",
        "test_loader = Data.DataLoader(\n",
        "        dataset=test_set, batch_size=30, shuffle=False)\n",
        "model.eval()\n",
        "outputs=[]\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (inputs, length) in enumerate(test_loader):\n",
        "            if n_gpu !=0:\n",
        "                inputs = inputs.cuda()\n",
        "            outputs.extend(model(inputs).detach().cpu().numpy())\n",
        "_,test_df[\"num_label\"]=torch.max(torch.tensor(outputs), 1)\n",
        "\n",
        "submit(test_df,\"mixText_self_train9.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 109540/109540 [00:00<00:00, 831953.93B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOH8jVMtYTsZ"
      },
      "source": [
        "def self_train( model,optimizer,scheduler,train_criterion,criterion,data_path,step,nlabels,\n",
        "               checkpoint_name=None,max_seq_len=256, model_type='bert-base-chinese', train_aug=False):\n",
        "  \n",
        "  tokenizer = BertTokenizer.from_pretrained(model_type)\n",
        "\n",
        "  def text_filter(sentence: str) -> str:\n",
        "        \"\"\"\n",
        "        过滤掉非汉字和标点符号和非数字\n",
        "        :param sentence:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        line = sentence.replace('\\n', '。')\n",
        "        # 过滤掉非汉字和标点符号和非数字\n",
        "        linelist = [word for word in line if\n",
        "                    word >= u'\\u4e00' and word <= u'\\u9fa5' or word in ['，', '。', '？', '！',\n",
        "                                                                        '：'] or word.isdigit()]\n",
        "        return ''.join(linelist)\n",
        "  def fliter_data(data):\n",
        "      data['content']=data['content'].astype(str)\n",
        "      data[\"text\"]=data[\"content\"].apply(lambda x:text_filter(x))\n",
        "      return data \n",
        "\n",
        "\n",
        "  train_labeled=pd.read_csv(data_path+\"/\"+str(step)+\"train.csv\")\n",
        "  valid_labeled=pd.read_csv(data_path+\"/valid.csv\")\n",
        "  train_ul=pd.read_csv(data_path+\"/\"+str(step)+\"train_ul.csv\")\n",
        "  test_df=pd.read_csv(data_path+\"/\"+str(step)+\"test_df.csv\")\n",
        "\n",
        "\n",
        "\n",
        "  train_labeled=fliter_data(train_labeled)\n",
        "  valid_labeled=fliter_data(valid_labeled)\n",
        "  train_ul=fliter_data(train_ul)\n",
        "  test_df=fliter_data(test_df)\n",
        "\n",
        "  total_unlabeled=pd.concat([train_ul,test_df])\n",
        "\n",
        "  train_labeled_set = loader_labeled(list(train_labeled[\"text\"]),list(train_labeled[\"num_label\"]), tokenizer, max_seq_len, train_aug)\n",
        "  train_unlabeled_set = loader_unlabeled(list(total_unlabeled[\"text\"]),tokenizer, max_seq_len, train_aug)\n",
        "  train_ul_set= loader_unlabeled(list(train_ul[\"text\"]),tokenizer, max_seq_len, train_aug)\n",
        "  val_set = loader_labeled(list(valid_labeled[\"text\"]),list(valid_labeled[\"num_label\"]), tokenizer, max_seq_len, train_aug)\n",
        "  test_set = loader_unlabeled(list(test_df[\"text\"]),tokenizer, max_seq_len, train_aug)\n",
        "\n",
        "  # 制作loader\n",
        "  labeled_trainloader = Data.DataLoader(\n",
        "        dataset=train_labeled_set, batch_size=args.batch_size, shuffle=True)\n",
        "  unlabeled_trainloader = Data.DataLoader(\n",
        "        dataset=train_unlabeled_set, batch_size=args.batch_size_u, shuffle=True)\n",
        "  ## use for self_training \n",
        "  unlabeled_trainloader2 = Data.DataLoader(\n",
        "        dataset=train_ul_set, batch_size=args.batch_size_u, shuffle=False)\n",
        "  val_loader = Data.DataLoader(\n",
        "        dataset=val_set, batch_size=20, shuffle=False)\n",
        "  test_loader = Data.DataLoader(\n",
        "        dataset=test_set, batch_size=20, shuffle=False)\n",
        "\n",
        "  #read model from prev train \n",
        "  #checkpoint=torch.load(checkpoint_name)\n",
        "  #model.load_state_dict(checkpoint)\n",
        "\n",
        "  #再次训练\n",
        "  for epoch in range(args.epochs):\n",
        "        args.train_aug=False\n",
        "        #调用train函数, 给定有标签数据，无标签数据，模型，优化器，损失函数，labels数量，是否数据增强\n",
        "        train(labeled_trainloader, unlabeled_trainloader, model, optimizer,scheduler, train_criterion, epoch, nlabels, 256,args.train_aug)\n",
        "\n",
        "        # scheduler.step()\n",
        "        # _, train_acc = validate(labeled_trainloader, model,  criterion, epoch, mode='Train Stats')\n",
        "        #print(\"epoch {}, train acc {}\".format(epoch, train_acc))\n",
        "\n",
        "        val_loss, val_acc = validate(val_loader, model, criterion, epoch, mode='Valid Stats')\n",
        "\n",
        "        print(\"epoch {}, 验证集准确率 {}, 验证集损失 {}\".format(epoch, val_acc, val_loss))\n",
        "\n",
        "        print('Epoch: ', epoch)\n",
        "        \n",
        "  ## make predict \n",
        "  append_df=pd.DataFrame([])\n",
        "  ## make a predict \n",
        "  outputs=[]\n",
        "  for batch_idx, (inputs, length) in enumerate(test_loader):\n",
        "            if n_gpu !=0:\n",
        "                inputs = inputs.cuda()\n",
        "            outputs.extend(model(inputs).detach().cpu().numpy())\n",
        "  ## add the high probility sample to train_data\n",
        "\n",
        "  ## 选择低熵样本\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "   outputs_u=torch.tensor(outputs)\n",
        "   test_df[\"entropy\"]=torch.sum(-F.softmax(outputs_u, dim=1) * F.log_softmax(outputs_u, dim=1), dim=1).cpu().numpy()\n",
        "   _,test_df[\"num_label\"]=torch.max(outputs_u, 1)\n",
        "   test_df=test_df.sort_values(\"entropy\").reset_index(drop=True)\n",
        "   append_df1=test_df.iloc[:int(0.1 * len(test_df)),]\n",
        "   test_df=test_df.iloc[int(0.1 * len(test_df)):,]\n",
        "   append_df=pd.concat([append_df,append_df1])\n",
        "\n",
        "  outputs=[]\n",
        "  for batch_idx, (inputs, length) in enumerate(unlabeled_trainloader2):\n",
        "            if n_gpu !=0:\n",
        "                inputs = inputs.cuda()\n",
        "            outputs.extend(model(inputs).detach().cpu().numpy())\n",
        "  ## add the high probility sample to train_data\n",
        "\n",
        "  ## 选择低熵样本\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    outputs_u=torch.tensor(outputs)\n",
        "    train_ul[\"entropy\"]=torch.sum(-F.softmax(outputs_u, dim=1) * F.log_softmax(outputs_u, dim=1), dim=1).cpu().numpy()\n",
        "    _,train_ul[\"num_label\"]=torch.max(outputs_u, 1)\n",
        "\n",
        "    train_ul=train_ul.sort_values(\"entropy\").reset_index(drop=True)\n",
        "    append_df2=train_ul.iloc[:int(0.1 * len(train_ul)),]\n",
        "    train_ul=train_ul.iloc[int(0.1 * len(train_ul)):,]\n",
        "    append_df=pd.concat([append_df,append_df2])\n",
        "\n",
        "  ## get new train_labeled,train_ul,test_df \n",
        "  train_labeled=pd.concat([train_labeled,append_df])\n",
        "  train_ul=train_ul\n",
        "  test_df=test_df \n",
        "\n",
        "  train_labeled.to_csv(data_path+\"/\"+str(step+1)+\"train.csv\",index=False)\n",
        "  train_ul.to_csv(data_path+\"/\"+str(step+1)+\"train_ul.csv\",index=False)\n",
        "  test_df.to_csv(data_path+\"/\"+str(step+1)+\"test_df.csv\",index=False)\n",
        "\n",
        "  #save model \n",
        "  torch.save(model.module.state_dict(), \"/content/drive/My Drive/MixText/code/model/self_train_model\"+str(step)+\".pt\")\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiRN5WFVEAvs",
        "outputId": "63ac1015-e746-4ed3-8fdd-f2de2e173741"
      },
      "source": [
        "self_train( model, optimizer,scheduler, train_criterion,criterion,\"../data/NLP2\",0,10,\n",
        "               checkpoint_name=None,max_seq_len=256, model_type='bert-base-chinese', train_aug=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 109540/109540 [00:00<00:00, 2748002.66B/s]\n",
            "/content/drive/My Drive/MixText/code/pytransformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0, step 0, loss 0.06372619420289993, Lx 0.06372619420289993, Lu 0.04901032894849777, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 0, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 0, 验证集准确率 0.8998512642538423, 验证集损失 0.41528084906289997\n",
            "Epoch:  0\n",
            "epoch 1, step 0, loss 0.16093216836452484, Lx 0.15840516984462738, Lu 0.0442013144493103, Lu2 0.03790486603975296\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 2, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 1, 验证集准确率 0.8760535448686168, 验证集损失 0.4716260166793515\n",
            "Epoch:  1\n",
            "epoch 2, step 0, loss 0.0760982558131218, Lx 0.0760982558131218, Lu 0.039917901158332825, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 2, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 2, 验证集准确率 0.894893406048587, 验证集损失 0.43765085858020913\n",
            "Epoch:  2\n",
            "epoch 3, step 0, loss 0.23894472420215607, Lx 0.23758544027805328, Lu 0.06527762115001678, Lu2 0.006796419620513916\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 0, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 3, 验证集准确率 0.8765493306891423, 验证集损失 0.4425763287163632\n",
            "Epoch:  3\n",
            "epoch 4, step 0, loss 0.3234766125679016, Lx 0.3215794265270233, Lu 0.12190469354391098, Lu2 0.007114484906196594\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 6, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 4, 验证集准确率 0.8517600396628656, 验证集损失 0.52672985778271\n",
            "Epoch:  4\n",
            "epoch 5, step 0, loss 0.44482478499412537, Lx 0.424466609954834, Lu 0.07278898358345032, Lu2 0.061074547469615936\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 0, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 5, 验证集准确率 0.8765493306891423, 验证集损失 0.4486739378815898\n",
            "Epoch:  5\n",
            "epoch 6, step 0, loss 0.36434170603752136, Lx 0.36434170603752136, Lu 0.048385702073574066, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 6, 验证集准确率 0.8934060485870104, 验证集损失 0.4401374471087118\n",
            "Epoch:  6\n",
            "epoch 7, step 0, loss 0.10283394157886505, Lx 0.10283394157886505, Lu 0.03731048107147217, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 7, 验证集准确率 0.8701041150223103, 验证集损失 0.5275406175517894\n",
            "Epoch:  7\n",
            "epoch 8, step 0, loss 1.9418312311172485, Lx 1.9402472972869873, Lu 0.10537674278020859, Lu2 0.002969905734062195\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 6, 0, 0, 5, 5, 4, 3, 5, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 8, 验证集准确率 0.8879524045612296, 验证集损失 0.4475763908813185\n",
            "Epoch:  8\n",
            "epoch 9, step 0, loss 0.7576239705085754, Lx 0.7505538463592529, Lu 0.034435417503118515, Lu2 0.011783535592257977\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 0, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 9, 验证集准确率 0.8934060485870104, 验证集损失 0.4237137377542851\n",
            "Epoch:  9\n",
            "epoch 10, step 0, loss 0.5038818120956421, Lx 0.5038818120956421, Lu 0.05019989609718323, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 10, 验证集准确率 0.8854734754586019, 验证集损失 0.45205958104098143\n",
            "Epoch:  10\n",
            "epoch 11, step 0, loss 0.5559357404708862, Lx 0.5559357404708862, Lu 0.03585938736796379, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 11, 验证集准确率 0.888448190381755, 验证集损失 0.42319564364691686\n",
            "Epoch:  11\n",
            "epoch 12, step 0, loss 0.12900318205356598, Lx 0.12900318205356598, Lu 0.035838425159454346, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 12, 验证集准确率 0.8963807635101636, 验证集损失 0.40171089773581176\n",
            "Epoch:  12\n",
            "epoch 13, step 0, loss 0.06669637560844421, Lx 0.06669637560844421, Lu 0.048530858010053635, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 13, 验证集准确率 0.8899355478433317, 验证集损失 0.4550718648574349\n",
            "Epoch:  13\n",
            "epoch 14, step 0, loss 0.058679208159446716, Lx 0.024158095940947533, Lu 0.0459708496928215, Lu2 0.036986902356147766\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 1, 7, 1, 0, 0, 9, 5, 0, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 14, 验证集准确率 0.8914229053049083, 验证集损失 0.42960856717502827\n",
            "Epoch:  14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggwf89X2KynQ",
        "outputId": "d3bbb3f5-2cda-49a6-aa7b-a72882661e2d"
      },
      "source": [
        "self_train( model, optimizer,scheduler, train_criterion,criterion,\"../data/NLP2\",1,10,\n",
        "               checkpoint_name=None,max_seq_len=256, model_type='bert-base-chinese', train_aug=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0, step 0, loss 0.5419917106628418, Lx 0.5419917106628418, Lu 0.04861962050199509, Lu2 0.008538400754332542\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 1, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 0, 验证集准确率 0.8839861179970253, 验证集损失 0.45276778645307403\n",
            "Epoch:  0\n",
            "epoch 1, step 0, loss 0.07909555733203888, Lx 0.07672975212335587, Lu 0.07046167552471161, Lu2 0.035487063229084015\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 1, 验证集准确率 0.8750619732275657, 验证集损失 0.47981369800507345\n",
            "Epoch:  1\n",
            "epoch 2, step 0, loss 0.5256173014640808, Lx 0.5256173014640808, Lu 0.03386594355106354, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 6, 0, 0, 5, 5, 4, 6, 2, 6, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 2, 验证集准确率 0.8329201784828953, 验证集损失 0.7131963372969308\n",
            "Epoch:  2\n",
            "epoch 3, step 0, loss 0.025123313069343567, Lx 0.0246664397418499, Lu 0.05989224463701248, Lu2 0.0022843680344522\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 3, 验证集准确率 0.8993554784333168, 验证集损失 0.4138330687271467\n",
            "Epoch:  3\n",
            "epoch 4, step 0, loss 0.06422177702188492, Lx 0.06422177702188492, Lu 0.03593699261546135, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 4, 验证集准确率 0.8919186911254338, 验证集损失 0.4626132077401265\n",
            "Epoch:  4\n",
            "epoch 5, step 0, loss 0.5352800488471985, Lx 0.53429114818573, Lu 0.05920649319887161, Lu2 0.002966776490211487\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 5, 验证集准确率 0.8557263262270699, 验证集损失 0.5881502912017338\n",
            "Epoch:  5\n",
            "epoch 6, step 0, loss 0.04131884500384331, Lx 0.034101154655218124, Lu 0.055239029228687286, Lu2 0.01804422400891781\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 6, 验证集准确率 0.8824987605354487, 验证集损失 0.4911886635995999\n",
            "Epoch:  6\n",
            "epoch 7, step 0, loss 0.03348881006240845, Lx 0.02535826712846756, Lu 0.08571003377437592, Lu2 0.017422592267394066\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 7, 验证集准确率 0.8924144769459593, 验证集损失 0.4445277049132781\n",
            "Epoch:  7\n",
            "epoch 8, step 0, loss 0.03911052644252777, Lx 0.03911052644252777, Lu 0.03773658722639084, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 8, 验证集准确率 0.8869608329201785, 验证集损失 0.4642187406336191\n",
            "Epoch:  8\n",
            "epoch 9, step 0, loss 0.5420942306518555, Lx 0.5420942306518555, Lu 0.02698727324604988, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 9, 验证集准确率 0.8939018344075359, 验证集损失 0.46092402868168625\n",
            "Epoch:  9\n",
            "epoch 10, step 0, loss 0.3540419042110443, Lx 0.3492403030395508, Lu 0.030231516808271408, Lu2 0.007202406879514456\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 10, 验证集准确率 0.8889439762022806, 验证集损失 0.4774423165558055\n",
            "Epoch:  10\n",
            "epoch 11, step 0, loss 0.5443700551986694, Lx 0.5398439168930054, Lu 0.04637657850980759, Lu2 0.006172006484121084\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 2, 2, 0, 5, 5, 4, 3, 2, 1, 2, 2, 1, 4, 1, 0, 9, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 11, 验证集准确率 0.8334159643034209, 验证集损失 0.6715930734064299\n",
            "Epoch:  11\n",
            "epoch 12, step 0, loss 0.14998206496238708, Lx 0.14595574140548706, Lu 0.03564973175525665, Lu2 0.005032907240092754\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 12, 验证集准确率 0.8929102627664849, 验证集损失 0.5001045718870366\n",
            "Epoch:  12\n",
            "epoch 13, step 0, loss 0.4995090365409851, Lx 0.4995090365409851, Lu 0.0409076064825058, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 1, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 2, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 13, 验证集准确率 0.8914229053049083, 验证集损失 0.4896933311650998\n",
            "Epoch:  13\n",
            "epoch 14, step 0, loss 0.03860802948474884, Lx 0.03860802948474884, Lu 0.017950354143977165, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 2, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 14, 验证集准确率 0.8899355478433317, 验证集损失 0.4665291051079746\n",
            "Epoch:  14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV38q2Bk3tyC",
        "outputId": "a3daa616-2703-4257-8218-a11f3f07d13a"
      },
      "source": [
        "self_train( model, optimizer,scheduler, train_criterion,criterion,\"../data/NLP2\",2,10,\n",
        "               checkpoint_name=None,max_seq_len=256, model_type='bert-base-chinese', train_aug=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0, step 0, loss 0.21014457941055298, Lx 0.21014457941055298, Lu 0.031090810894966125, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 0, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 0, 验证集准确率 0.8834903321764997, 验证集损失 0.4970236609389301\n",
            "Epoch:  0\n",
            "epoch 1, step 0, loss 0.05465487390756607, Lx 0.05465487390756607, Lu 0.043505966663360596, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 1, 验证集准确率 0.887456618740704, 验证集损失 0.4873255893004431\n",
            "Epoch:  1\n",
            "epoch 2, step 0, loss 0.2523789405822754, Lx 0.2510702610015869, Lu 0.11290355771780014, Lu2 0.009814992547035217\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 0, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 2, 验证集准确率 0.8805156172533466, 验证集损失 0.5223704249324276\n",
            "Epoch:  2\n",
            "epoch 3, step 0, loss 0.027207398787140846, Lx 0.027207398787140846, Lu 0.04266129061579704, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 3, 验证集准确率 0.880019831432821, 验证集损失 0.5361608486580092\n",
            "Epoch:  3\n",
            "epoch 4, step 0, loss 0.34259381890296936, Lx 0.34259381890296936, Lu 0.02986132726073265, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 4, 验证集准确率 0.8869608329201785, 验证集损失 0.49362725756386455\n",
            "Epoch:  4\n",
            "epoch 5, step 0, loss 0.48359373211860657, Lx 0.4795403480529785, Lu 0.07539520412683487, Lu2 0.012160142883658409\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 5, 验证集准确率 0.894893406048587, 验证集损失 0.43669477433527704\n",
            "Epoch:  5\n",
            "epoch 6, step 0, loss 0.561052680015564, Lx 0.5563743114471436, Lu 0.07437749207019806, Lu2 0.011695891618728638\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 6, 验证集准确率 0.8765493306891423, 验证集损失 0.5178232379793294\n",
            "Epoch:  6\n",
            "epoch 7, step 0, loss 0.38855886459350586, Lx 0.38855886459350586, Lu 0.054609935730695724, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 0, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 7, 验证集准确率 0.8924144769459593, 验证集损失 0.4761442406953534\n",
            "Epoch:  7\n",
            "epoch 8, step 0, loss 0.03129439055919647, Lx 0.027968836948275566, Lu 0.08367832750082016, Lu2 0.006235410925000906\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 8, 验证集准确率 0.8939018344075359, 验证集损失 0.4727267942469369\n",
            "Epoch:  8\n",
            "epoch 9, step 0, loss 0.04690860956907272, Lx 0.026355065405368805, Lu 0.03008298948407173, Lu2 0.03425590693950653\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 0, 6, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 9, 验证集准确率 0.8254833911750123, 验证集损失 0.7104879394210561\n",
            "Epoch:  9\n",
            "epoch 10, step 0, loss 0.013558846898376942, Lx 0.013558846898376942, Lu 0.028312426060438156, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 10, 验证集准确率 0.8745661874070402, 验证集损失 0.5421274002672838\n",
            "Epoch:  10\n",
            "epoch 11, step 0, loss 0.020258840173482895, Lx 0.019349711015820503, Lu 0.04290168732404709, Lu2 0.0012397220125421882\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 5, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 11, 验证集准确率 0.849281110560238, 验证集损失 0.6414126200314259\n",
            "Epoch:  11\n",
            "epoch 12, step 0, loss 0.15663684904575348, Lx 0.1536647379398346, Lu 0.029714753851294518, Lu2 0.003715142607688904\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 0, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 12, 验证集准确率 0.8859692612791275, 验证集损失 0.4723664138117047\n",
            "Epoch:  12\n",
            "epoch 13, step 0, loss 0.46201154589653015, Lx 0.454115629196167, Lu 0.08068954199552536, Lu2 0.009110679849982262\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 13, 验证集准确率 0.8839861179970253, 验证集损失 0.5055512936548484\n",
            "Epoch:  13\n",
            "epoch 14, step 0, loss 0.5658817291259766, Lx 0.560084342956543, Lu 0.02142358385026455, Lu2 0.006211509462445974\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 2, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 14, 验证集准确率 0.8760535448686168, 验证集损失 0.529149391196657\n",
            "Epoch:  14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuJAI9yy5UI8",
        "outputId": "32866aed-1184-4ebf-99b5-624178f5d21e"
      },
      "source": [
        "self_train( model, optimizer,scheduler, train_criterion,criterion,\"../data/NLP2\",3,10,\n",
        "               checkpoint_name=None,max_seq_len=256, model_type='bert-base-chinese', train_aug=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MixText/code/pytransformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0, step 0, loss 0.5243107080459595, Lx 0.5243107080459595, Lu 0.17948952317237854, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 0, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 0, 验证集准确率 0.8790282597917699, 验证集损失 0.5058592915069543\n",
            "Epoch:  0\n",
            "epoch 1, step 0, loss 0.4281255006790161, Lx 0.4281255006790161, Lu 0.04600412771105766, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 1, 验证集准确率 0.8904313336638572, 验证集损失 0.4976002755706477\n",
            "Epoch:  1\n",
            "epoch 2, step 0, loss 0.6373498439788818, Lx 0.6373498439788818, Lu 0.030975280329585075, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 2, 验证集准确率 0.8755577590480912, 验证集损失 0.5394748519398697\n",
            "Epoch:  2\n",
            "epoch 3, step 0, loss 0.27700960636138916, Lx 0.27700960636138916, Lu 0.03218468651175499, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 3, 验证集准确率 0.8785324739712445, 验证集损失 0.5822024242596929\n",
            "Epoch:  3\n",
            "epoch 4, step 0, loss 0.022926650941371918, Lx 0.018349800258874893, Lu 0.17396998405456543, Lu2 0.017163192853331566\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 2, 0, 0, 5, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 4, 验证集准确率 0.8220128904313336, 验证集损失 0.8753317286162077\n",
            "Epoch:  4\n",
            "epoch 5, step 0, loss 0.036548346281051636, Lx 0.036548346281051636, Lu 0.033531755208969116, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 5, 验证集准确率 0.8765493306891423, 验证集损失 0.58200568301316\n",
            "Epoch:  5\n",
            "epoch 6, step 0, loss 0.2502051889896393, Lx 0.2502051889896393, Lu 0.047309961169958115, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 6, 验证集准确率 0.8676251859196827, 验证集损失 0.6124059216081948\n",
            "Epoch:  6\n",
            "epoch 7, step 0, loss 0.36836594343185425, Lx 0.36703866720199585, Lu 0.04289636015892029, Lu2 0.002844184637069702\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 7, 验证集准确率 0.8720872583044125, 验证集损失 0.5952393080693812\n",
            "Epoch:  7\n",
            "epoch 8, step 0, loss 0.345776230096817, Lx 0.3440876007080078, Lu 0.12297703325748444, Lu2 0.0031661740504205227\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 6, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 8, 验证集准确率 0.857709469509172, 验证集损失 0.6645761988632266\n",
            "Epoch:  8\n",
            "epoch 9, step 0, loss 0.4987199306488037, Lx 0.47854435443878174, Lu 0.052610546350479126, Lu2 0.03362596035003662\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 2, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 9, 验证集准确率 0.8790282597917699, 验证集损失 0.5705636730385287\n",
            "Epoch:  9\n",
            "epoch 10, step 0, loss 0.2693231999874115, Lx 0.2693231999874115, Lu 0.0251079760491848, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 2, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 10, 验证集准确率 0.8730788299454636, 验证集损失 0.6000663336804142\n",
            "Epoch:  10\n",
            "epoch 11, step 0, loss 0.016644679009914398, Lx 0.016644679009914398, Lu 0.019111618399620056, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 4, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 11, 验证集准确率 0.8879524045612296, 验证集损失 0.5009818298868691\n",
            "Epoch:  11\n",
            "epoch 12, step 0, loss 0.38715875148773193, Lx 0.38715875148773193, Lu 0.05308232828974724, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 12, 验证集准确率 0.866137828458106, 验证集损失 0.6389613314487879\n",
            "Epoch:  12\n",
            "epoch 13, step 0, loss 0.016827788203954697, Lx 0.016827788203954697, Lu 0.039506614208221436, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 13, 验证集准确率 0.8745661874070402, 验证集损失 0.5539668891015594\n",
            "Epoch:  13\n",
            "epoch 14, step 0, loss 0.12200614809989929, Lx 0.12200614809989929, Lu 0.04015376418828964, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 14, 验证集准确率 0.8760535448686168, 验证集损失 0.5701487756523096\n",
            "Epoch:  14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxeBZ0kCgofW",
        "outputId": "04eac8c0-2f4a-4523-ea08-185edb419162"
      },
      "source": [
        "self_train( model, optimizer,scheduler, train_criterion,criterion,\"../data/NLP2\",4,10,\n",
        "               checkpoint_name=None,max_seq_len=256, model_type='bert-base-chinese', train_aug=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0, step 0, loss 0.33009451627731323, Lx 0.33009451627731323, Lu 0.044966455549001694, Lu2 0.015052437782287598\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 0, 验证集准确率 0.8790282597917699, 验证集损失 0.5588520097411914\n",
            "Epoch:  0\n",
            "epoch 1, step 0, loss 0.8526284694671631, Lx 0.8526284694671631, Lu 0.031071756035089493, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 1, 验证集准确率 0.8815071888943976, 验证集损失 0.5478341435338521\n",
            "Epoch:  1\n",
            "epoch 2, step 0, loss 0.5372110605239868, Lx 0.5372110605239868, Lu 0.01795952580869198, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 6, 0, 0, 9, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 2, 验证集准确率 0.8497768963807635, 验证集损失 0.6130499365339199\n",
            "Epoch:  2\n",
            "epoch 3, step 0, loss 0.021085934713482857, Lx 0.01893869787454605, Lu 0.03872865065932274, Lu2 0.010736187919974327\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 2, 0, 0, 9, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 3, 验证集准确率 0.8705999008428359, 验证集损失 0.5707989208285739\n",
            "Epoch:  3\n",
            "epoch 4, step 0, loss 0.6931787729263306, Lx 0.6931787729263306, Lu 0.0294046588242054, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 2, 7, 2, 0, 0, 9, 5, 4, 3, 2, 1, 2, 6, 1, 4, 2, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 4, 验证集准确率 0.8482895389191869, 验证集损失 0.6209510277567019\n",
            "Epoch:  4\n",
            "epoch 5, step 0, loss 0.7615117430686951, Lx 0.7595558762550354, Lu 0.06622625142335892, Lu2 0.00586758553981781\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 2, 0, 0, 9, 5, 0, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 5, 验证集准确率 0.8790282597917699, 验证集损失 0.5592000282336771\n",
            "Epoch:  5\n",
            "epoch 6, step 0, loss 0.6038821935653687, Lx 0.6014201641082764, Lu 0.04872732609510422, Lu2 0.006155034061521292\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 2, 0, 0, 9, 5, 0, 3, 5, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 6, 验证集准确率 0.8815071888943976, 验证集损失 0.515862631602753\n",
            "Epoch:  6\n",
            "epoch 7, step 0, loss 0.34911495447158813, Lx 0.3418881893157959, Lu 0.045812658965587616, Lu2 0.015485918149352074\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 0, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 7, 验证集准确率 0.8844819038175508, 验证集损失 0.5406894841345454\n",
            "Epoch:  7\n",
            "epoch 8, step 0, loss 0.0497233010828495, Lx 0.048977989703416824, Lu 0.08200109004974365, Lu2 0.0013974558096379042\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 4, 0, 0, 9, 5, 0, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 8, 验证集准确率 0.888448190381755, 验证集损失 0.5398590625085982\n",
            "Epoch:  8\n",
            "epoch 9, step 0, loss 0.41621071100234985, Lx 0.4082755446434021, Lu 0.0483645461499691, Lu2 0.013225257396697998\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 2, 0, 0, 5, 5, 0, 3, 2, 1, 2, 2, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 9, 验证集准确率 0.880019831432821, 验证集损失 0.5751820116400365\n",
            "Epoch:  9\n",
            "epoch 10, step 0, loss 0.9514787197113037, Lx 0.9491512775421143, Lu 0.04748252034187317, Lu2 0.0034911285620182753\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 6, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 10, 验证集准确率 0.8839861179970253, 验证集损失 0.5657740211281436\n",
            "Epoch:  10\n",
            "epoch 11, step 0, loss 0.4119313955307007, Lx 0.4119313955307007, Lu 0.02690749429166317, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 6, 0, 5, 5, 2, 3, 2, 1, 2, 2, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 11, 验证集准确率 0.8596926127912742, 验证集损失 0.6673871481779133\n",
            "Epoch:  11\n",
            "epoch 12, step 0, loss 0.6607282161712646, Lx 0.6607282161712646, Lu 0.039480313658714294, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 6, 0, 9, 5, 4, 3, 5, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 12, 验证集准确率 0.849281110560238, 验证集损失 0.6941960426652319\n",
            "Epoch:  12\n",
            "epoch 13, step 0, loss 0.6062161326408386, Lx 0.590280294418335, Lu 0.10245935618877411, Lu2 0.018387477844953537\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 6, 0, 9, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 13, 验证集准确率 0.8636588993554785, 验证集损失 0.6484422043379605\n",
            "Epoch:  13\n",
            "epoch 14, step 0, loss 0.011010833084583282, Lx 0.011010833084583282, Lu 0.036961667239665985, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 0, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 14, 验证集准确率 0.8745661874070402, 验证集损失 0.570389273650778\n",
            "Epoch:  14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Uw244tzgp70",
        "outputId": "f44d9650-88a6-4a73-a9f6-25cd68149a49"
      },
      "source": [
        "self_train( model, optimizer,scheduler, train_criterion,criterion,\"../data/NLP2\",5,10,\n",
        "               checkpoint_name=None,max_seq_len=256, model_type='bert-base-chinese', train_aug=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0, step 0, loss 0.22489199042320251, Lx 0.22489199042320251, Lu 0.02667880430817604, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 4, 3, 2, 1, 2, 2, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 0, 验证集准确率 0.8750619732275657, 验证集损失 0.5648630433667398\n",
            "Epoch:  0\n",
            "epoch 1, step 0, loss 0.1725761890411377, Lx 0.1725761890411377, Lu 0.03718619793653488, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 4, 3, 2, 1, 2, 2, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 1, 验证集准确率 0.880019831432821, 验证集损失 0.5291146788456148\n",
            "Epoch:  1\n",
            "epoch 2, step 0, loss 0.5069714784622192, Lx 0.5054399967193604, Lu 0.036388788372278214, Lu2 0.011486157774925232\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 2, 验证集准确率 0.8755577590480912, 验证集损失 0.5612540667859055\n",
            "Epoch:  2\n",
            "epoch 3, step 0, loss 0.06260670721530914, Lx 0.06260670721530914, Lu 0.04363347217440605, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 0, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 3, 验证集准确率 0.8671294000991572, 验证集损失 0.5914207674197236\n",
            "Epoch:  3\n",
            "epoch 4, step 0, loss 0.21415920555591583, Lx 0.2108728289604187, Lu 0.0959521234035492, Lu2 0.012323891744017601\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 0, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 4, 验证集准确率 0.8785324739712445, 验证集损失 0.5843130593207961\n",
            "Epoch:  4\n",
            "epoch 5, step 0, loss 0.007101459428668022, Lx 0.007101459428668022, Lu 0.04222326725721359, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 5, 验证集准确率 0.8760535448686168, 验证集损失 0.6213902396601974\n",
            "Epoch:  5\n",
            "epoch 6, step 0, loss 0.7362310290336609, Lx 0.7313224077224731, Lu 0.02749168686568737, Lu2 0.012271558865904808\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 6, 验证集准确率 0.8834903321764997, 验证集损失 0.5550155772111413\n",
            "Epoch:  6\n",
            "epoch 7, step 0, loss 0.5693292617797852, Lx 0.5693292617797852, Lu 0.038958001881837845, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 2, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 7, 验证集准确率 0.8705999008428359, 验证集损失 0.6621352345135523\n",
            "Epoch:  7\n",
            "epoch 8, step 0, loss 0.6146828532218933, Lx 0.6040803790092468, Lu 0.03497658669948578, Lu2 0.01987968385219574\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 5, 1, 2, 2, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 8, 验证集准确率 0.8770451165096679, 验证集损失 0.6103201998258263\n",
            "Epoch:  8\n",
            "epoch 9, step 0, loss 0.45693978667259216, Lx 0.45693978667259216, Lu 0.013672204688191414, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 9, 验证集准确率 0.8676251859196827, 验证集损失 0.6325807398315344\n",
            "Epoch:  9\n",
            "epoch 10, step 0, loss 0.36800912022590637, Lx 0.36800912022590637, Lu 0.024734599515795708, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 4, 0, 0, 5, 5, 4, 3, 2, 1, 2, 2, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 10, 验证集准确率 0.8681209717402082, 验证集损失 0.6613062190452482\n",
            "Epoch:  10\n",
            "epoch 11, step 0, loss 0.7077189683914185, Lx 0.7077189683914185, Lu 0.030968554317951202, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 4, 6, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 11, 验证集准确率 0.8705999008428359, 验证集损失 0.5922868090820714\n",
            "Epoch:  11\n",
            "epoch 12, step 0, loss 0.36189642548561096, Lx 0.36179178953170776, Lu 0.03811786696314812, Lu2 0.00013080736971460283\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 4, 0, 0, 9, 5, 4, 3, 2, 1, 0, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 12, 验证集准确率 0.8433316807139316, 验证集损失 0.7424330782324415\n",
            "Epoch:  12\n",
            "epoch 13, step 0, loss 0.01959058828651905, Lx 0.012427081353962421, Lu 0.023001965135335922, Lu2 0.008265584707260132\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 13, 验证集准确率 0.8750619732275657, 验证集损失 0.5528831035046513\n",
            "Epoch:  13\n",
            "epoch 14, step 0, loss 0.47989216446876526, Lx 0.47989216446876526, Lu 0.025461599230766296, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 4, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 14, 验证集准确率 0.8705999008428359, 验证集损失 0.6327152138019058\n",
            "Epoch:  14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yqF0KgkgsQR",
        "outputId": "73e30a8a-d151-4150-8e56-3af603ff4231"
      },
      "source": [
        "self_train( model, optimizer,scheduler, train_criterion,criterion,\"../data/NLP2\",6,10,\n",
        "               checkpoint_name=None,max_seq_len=256, model_type='bert-base-chinese', train_aug=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0, step 0, loss 0.19834604859352112, Lx 0.19834604859352112, Lu 0.031504444777965546, Lu2 0.011127566918730736\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 4, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 0, 验证集准确率 0.8790282597917699, 验证集损失 0.5792128899507317\n",
            "Epoch:  0\n",
            "epoch 1, step 0, loss 0.013078122399747372, Lx 0.013078122399747372, Lu 0.18781745433807373, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 4, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 1, 验证集准确率 0.8696083292017849, 验证集损失 0.6456562662197034\n",
            "Epoch:  1\n",
            "epoch 2, step 0, loss 0.012936396524310112, Lx 0.011392618529498577, Lu 0.12902066111564636, Lu2 0.011578336358070374\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 4, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 2, 验证集准确率 0.8705999008428359, 验证集损失 0.6046212876735493\n",
            "Epoch:  2\n",
            "epoch 3, step 0, loss 0.03331640362739563, Lx 0.029788969084620476, Lu 0.06431027501821518, Lu2 0.017637163400650024\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 4, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 3, 验证集准确率 0.8671294000991572, 验证集损失 0.634050997287168\n",
            "Epoch:  3\n",
            "epoch 4, step 0, loss 0.1911436766386032, Lx 0.18859830498695374, Lu 0.12231345474720001, Lu2 0.009545142762362957\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 4, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 4, 验证集准确率 0.8676251859196827, 验证集损失 0.7322965128939224\n",
            "Epoch:  4\n",
            "epoch 5, step 0, loss 0.25186872482299805, Lx 0.2509632706642151, Lu 0.028695156797766685, Lu2 0.0027163426857441664\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 4, 0, 0, 5, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 5, 验证集准确率 0.8572136836886465, 验证集损失 0.6854779135415503\n",
            "Epoch:  5\n",
            "epoch 6, step 0, loss 0.4536587595939636, Lx 0.4536587595939636, Lu 0.028384311124682426, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 4, 0, 0, 9, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 6, 验证集准确率 0.8696083292017849, 验证集损失 0.6383530254492856\n",
            "Epoch:  6\n",
            "epoch 7, step 0, loss 0.013573579490184784, Lx 0.013573579490184784, Lu 0.02683793567121029, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 0, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 7, 验证集准确率 0.8710956866633615, 验证集损失 0.7005816387454944\n",
            "Epoch:  7\n",
            "epoch 8, step 0, loss 0.42325299978256226, Lx 0.42238038778305054, Lu 0.07625739276409149, Lu2 0.001636167406104505\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 2, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 8, 验证集准确率 0.880019831432821, 验证集损失 0.5418443474687735\n",
            "Epoch:  8\n",
            "epoch 9, step 0, loss 0.2324770987033844, Lx 0.22215411067008972, Lu 0.07300285249948502, Lu2 0.017204970121383667\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 6, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 9, 验证集准确率 0.8854734754586019, 验证集损失 0.5556896281311816\n",
            "Epoch:  9\n",
            "epoch 10, step 0, loss 0.6730687618255615, Lx 0.6680676341056824, Lu 0.044061899185180664, Lu2 0.007501676678657532\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 6, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 10, 验证集准确率 0.8820029747149232, 验证集损失 0.6189452881177256\n",
            "Epoch:  10\n",
            "epoch 11, step 0, loss 0.22728495299816132, Lx 0.1858515441417694, Lu 0.17768225073814392, Lu2 0.05650010332465172\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 6, 6, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 11, 验证集准确率 0.8760535448686168, 验证集损失 0.634962259729457\n",
            "Epoch:  11\n",
            "epoch 12, step 0, loss 0.4333219826221466, Lx 0.4333219826221466, Lu 0.05256413668394089, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 12, 验证集准确率 0.8770451165096679, 验证集损失 0.6315191128080176\n",
            "Epoch:  12\n",
            "epoch 13, step 0, loss 0.4242596924304962, Lx 0.41700688004493713, Lu 0.06566829979419708, Lu2 0.008368616923689842\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 13, 验证集准确率 0.8656420426375806, 验证集损失 0.6706352607893306\n",
            "Epoch:  13\n",
            "epoch 14, step 0, loss 0.7800613045692444, Lx 0.7800613045692444, Lu 0.040569618344306946, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 14, 验证集准确率 0.8606841844323252, 验证集损失 0.7406734768255074\n",
            "Epoch:  14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ng-ov3F_gt2r",
        "outputId": "4572c257-cc2f-4f6e-90ee-129a0e1a8c84"
      },
      "source": [
        "self_train( model, optimizer,scheduler, train_criterion,criterion,\"../data/NLP2\",7,10,\n",
        "               checkpoint_name=None,max_seq_len=256, model_type='bert-base-chinese', train_aug=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0, step 0, loss 0.36285215616226196, Lx 0.36285215616226196, Lu 0.020751729607582092, Lu2 0.003670449135825038\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 1, 0, 5, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 0, 验证集准确率 0.8309370352007932, 验证集损失 0.7790100058752177\n",
            "Epoch:  0\n",
            "epoch 1, step 0, loss 0.049982283264398575, Lx 0.049982283264398575, Lu 0.046333372592926025, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 1, 验证集准确率 0.8542389687654933, 验证集损失 0.7468219656528639\n",
            "Epoch:  1\n",
            "epoch 2, step 0, loss 0.740126371383667, Lx 0.740126371383667, Lu 0.021113257855176926, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 2, 验证集准确率 0.856717897868121, 验证集损失 0.7169522681007098\n",
            "Epoch:  2\n",
            "epoch 3, step 0, loss 0.029824241995811462, Lx 0.029824241995811462, Lu 0.017988810315728188, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 0, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 3, 验证集准确率 0.8497768963807635, 验证集损失 0.7394875129726363\n",
            "Epoch:  3\n",
            "epoch 4, step 0, loss 0.025661446154117584, Lx 0.025661446154117584, Lu 0.016222316771745682, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 4, 验证集准确率 0.8750619732275657, 验证集损失 0.6497831579369812\n",
            "Epoch:  4\n",
            "epoch 5, step 0, loss 0.3365151584148407, Lx 0.3364115357398987, Lu 0.025300923734903336, Lu2 0.0003108730015810579\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 5, 验证集准确率 0.8765493306891423, 验证集损失 0.6386155747080358\n",
            "Epoch:  5\n",
            "epoch 6, step 0, loss 0.031267810612916946, Lx 0.031267810612916946, Lu 0.03270205855369568, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 6, 验证集准确率 0.8740704015865146, 验证集损失 0.6488672091958543\n",
            "Epoch:  6\n",
            "epoch 7, step 0, loss 0.35759198665618896, Lx 0.35308700799942017, Lu 0.03945622965693474, Lu2 0.00965350866317749\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 7, 验证集准确率 0.8616757560733763, 验证集损失 0.7287262427663531\n",
            "Epoch:  7\n",
            "epoch 8, step 0, loss 0.3088555335998535, Lx 0.3050158619880676, Lu 0.05213826149702072, Lu2 0.007199381943792105\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 8, 验证集准确率 0.8468021814576103, 验证集损失 0.7397421458879201\n",
            "Epoch:  8\n",
            "epoch 9, step 0, loss 0.38789328932762146, Lx 0.3877459764480591, Lu 0.037812989205121994, Lu2 0.00024550658417865634\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 6, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 9, 验证集准确率 0.8542389687654933, 验证集损失 0.6863933580885533\n",
            "Epoch:  9\n",
            "epoch 10, step 0, loss 0.10269702225923538, Lx 0.10269702225923538, Lu 0.0201485026627779, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 10, 验证集准确率 0.8701041150223103, 验证集损失 0.618392089912811\n",
            "Epoch:  10\n",
            "epoch 11, step 0, loss 0.03653154522180557, Lx 0.03653154522180557, Lu 0.03086499124765396, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 11, 验证集准确率 0.8433316807139316, 验证集损失 0.7997961618434721\n",
            "Epoch:  11\n",
            "epoch 12, step 0, loss 0.3625745475292206, Lx 0.3625745475292206, Lu 0.027811577543616295, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 12, 验证集准确率 0.8472979672781359, 验证集损失 0.7694967479828744\n",
            "Epoch:  12\n",
            "epoch 13, step 0, loss 0.5460703372955322, Lx 0.5460703372955322, Lu 0.3374393582344055, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 1, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 13, 验证集准确率 0.8487853247397125, 验证集损失 0.7278815271812142\n",
            "Epoch:  13\n",
            "epoch 14, step 0, loss 0.9482073783874512, Lx 0.9482073783874512, Lu 0.025874271988868713, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 14, 验证集准确率 0.8701041150223103, 验证集损失 0.6232230506678531\n",
            "Epoch:  14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o07mt_w7gvHZ",
        "outputId": "85f7f155-c644-49b1-cbef-9ff11b437834"
      },
      "source": [
        "self_train( model, optimizer,scheduler, train_criterion,criterion,\"../data/NLP2\",8,10,\n",
        "               checkpoint_name=None,max_seq_len=256, model_type='bert-base-chinese', train_aug=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0, step 0, loss 0.5420262813568115, Lx 0.5420262813568115, Lu 0.01122494786977768, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 4, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 0, 验证集准确率 0.865146256817055, 验证集损失 0.6948953244353085\n",
            "Epoch:  0\n",
            "epoch 1, step 0, loss 0.35414549708366394, Lx 0.35414549708366394, Lu 0.03165385499596596, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 4, 0, 0, 5, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 1, 验证集准确率 0.866137828458106, 验证集损失 0.6569095668879309\n",
            "Epoch:  1\n",
            "epoch 2, step 0, loss 0.01323101669549942, Lx 0.011589540168642998, Lu 0.06636351346969604, Lu2 0.012311076745390892\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 2, 验证集准确率 0.8537431829449678, 验证集损失 0.6855007731750511\n",
            "Epoch:  2\n",
            "epoch 3, step 0, loss 0.2619663178920746, Lx 0.25879690051078796, Lu 0.052578404545784, Lu2 0.015847112983465195\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 3, 验证集准确率 0.872583044124938, 验证集损失 0.5558897918981376\n",
            "Epoch:  3\n",
            "epoch 4, step 0, loss 0.25946760177612305, Lx 0.25638091564178467, Lu 0.08173346519470215, Lu2 0.011575018987059593\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 4, 6, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 4, 验证集准确率 0.8790282597917699, 验证集损失 0.6424551494825903\n",
            "Epoch:  4\n",
            "epoch 5, step 0, loss 0.019793502986431122, Lx 0.019793502986431122, Lu 0.04431851953268051, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 5, 验证集准确率 0.8720872583044125, 验证集损失 0.6304391510433707\n",
            "Epoch:  5\n",
            "epoch 6, step 0, loss 0.24609854817390442, Lx 0.24609854817390442, Lu 0.07436735183000565, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 6, 验证集准确率 0.8611799702528508, 验证集损失 0.6778600588256201\n",
            "Epoch:  6\n",
            "epoch 7, step 0, loss 0.04623578488826752, Lx 0.04623578488826752, Lu 0.05340870842337608, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 6, 0, 5, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 7, 验证集准确率 0.8562221120475955, 验证集损失 0.793950360386559\n",
            "Epoch:  7\n",
            "epoch 8, step 0, loss 0.30189278721809387, Lx 0.30189278721809387, Lu 0.029347386211156845, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 4, 6, 0, 5, 5, 4, 3, 2, 1, 2, 2, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 8, 验证集准确率 0.8720872583044125, 验证集损失 0.6571613382742023\n",
            "Epoch:  8\n",
            "epoch 9, step 0, loss 0.10746809840202332, Lx 0.10746809840202332, Lu 0.020079534500837326, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 6, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 9, 验证集准确率 0.8740704015865146, 验证集损失 0.6929527079048403\n",
            "Epoch:  9\n",
            "epoch 10, step 0, loss 0.527215838432312, Lx 0.527215838432312, Lu 0.01854041963815689, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 9, 5, 0, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 10, 验证集准确率 0.8740704015865146, 验证集损失 0.6545362810229806\n",
            "Epoch:  10\n",
            "epoch 11, step 0, loss 0.2712329924106598, Lx 0.2712329924106598, Lu 0.024065162986516953, Lu2 0.0\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 6, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 11, 验证集准确率 0.881011403073872, 验证集损失 0.6539328565094278\n",
            "Epoch:  11\n",
            "epoch 12, step 0, loss 0.16218145191669464, Lx 0.15865446627140045, Lu 0.07042719423770905, Lu2 0.004408732056617737\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 12, 验证集准确率 0.8512642538423401, 验证集损失 0.7319816890319031\n",
            "Epoch:  12\n",
            "epoch 13, step 0, loss 0.2631666362285614, Lx 0.26093390583992004, Lu 0.04915831610560417, Lu2 0.0025762319564819336\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 4, 0, 0, 5, 5, 4, 3, 2, 1, 2, 3, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 13, 验证集准确率 0.8537431829449678, 验证集损失 0.7213491031703348\n",
            "Epoch:  13\n",
            "epoch 14, step 0, loss 0.11934088170528412, Lx 0.11424034833908081, Lu 0.07693681120872498, Lu2 0.00546485697850585\n",
            "Sample some true labeles and predicted labels\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "tensor([0, 3, 7, 1, 0, 0, 5, 5, 4, 3, 2, 1, 2, 6, 1, 4, 1, 0, 3, 3],\n",
            "       device='cuda:0')\n",
            "epoch 14, 验证集准确率 0.8710956866633615, 验证集损失 0.6659117669779503\n",
            "Epoch:  14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3itUncFgwV9"
      },
      "source": [
        "self_train( model, optimizer,scheduler, train_criterion,criterion,\"../data/NLP2\",9,10,\n",
        "               checkpoint_name=None,max_seq_len=256, model_type='bert-base-chinese', train_aug=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuSuf9wygybQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}